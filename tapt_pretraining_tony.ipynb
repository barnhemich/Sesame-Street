{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tapt_pretraining_tony","provenance":[{"file_id":"1WlSRnkAZXAYMIC9N9TXtf5KH1ZI2NTya","timestamp":1650135291264}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6fc3d23c401a4109aa4c13f0f9c3dda9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e6a27c04c9647e59bde8f8919b27ed1","IPY_MODEL_331e4f67839640e290c6c806bd2de719","IPY_MODEL_263de68477424e9fabbcc1cc02e3983f"],"layout":"IPY_MODEL_a600825e8dc74d59b70ba7c0b05f5ec9"}},"3e6a27c04c9647e59bde8f8919b27ed1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a267ac3dad9b43e5ab9355a2821ea855","placeholder":"​","style":"IPY_MODEL_cb65442a86244f13b109f321f295497b","value":"100%"}},"331e4f67839640e290c6c806bd2de719":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5809ef0a7d334e6aabab89792c3fefa8","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc810e4058ee4ec4a9ccaea3794c90d6","value":3}},"263de68477424e9fabbcc1cc02e3983f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84424a3d295f49f6ad3cb5b4784a2977","placeholder":"​","style":"IPY_MODEL_dbfa6b32fcc24c0fb28f7d627a1c37a0","value":" 3/3 [00:00&lt;00:00, 83.36it/s]"}},"a600825e8dc74d59b70ba7c0b05f5ec9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a267ac3dad9b43e5ab9355a2821ea855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb65442a86244f13b109f321f295497b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5809ef0a7d334e6aabab89792c3fefa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc810e4058ee4ec4a9ccaea3794c90d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84424a3d295f49f6ad3cb5b4784a2977":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbfa6b32fcc24c0fb28f7d627a1c37a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26592c2ce3b64d379c49a59b002d68bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04786ad40b8a4fcfb5b11e1ea059be21","IPY_MODEL_f0ebeca5e6f84e5f890929fc93656613","IPY_MODEL_f76d7ffa66e54970a16bdafc0b02b0cb"],"layout":"IPY_MODEL_d71acf9e067b4762ae39502490a93efd"}},"04786ad40b8a4fcfb5b11e1ea059be21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff5cb95207394f86a558e38c85b08a3c","placeholder":"​","style":"IPY_MODEL_17cabfba4e524a19a2d01ce3399021a1","value":"100%"}},"f0ebeca5e6f84e5f890929fc93656613":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_036483b7590a4cad987b8c42285fcfe6","max":3219,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65f4dac699c441dfa199161e937df51c","value":3219}},"f76d7ffa66e54970a16bdafc0b02b0cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd6783b350a4dd8b07f36f5c3119d9d","placeholder":"​","style":"IPY_MODEL_fe01d87e820740fc87e2c60cf8f0f744","value":" 3219/3219 [00:00&lt;00:00, 4133.43ex/s]"}},"d71acf9e067b4762ae39502490a93efd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff5cb95207394f86a558e38c85b08a3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17cabfba4e524a19a2d01ce3399021a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"036483b7590a4cad987b8c42285fcfe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65f4dac699c441dfa199161e937df51c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dd6783b350a4dd8b07f36f5c3119d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe01d87e820740fc87e2c60cf8f0f744":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e770d4a9e3641b8a2a4e7c90afb57a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd0ec48c1777494db1330046f15411df","IPY_MODEL_73e1d32b91ad4e3dbde0ea0fde008e10","IPY_MODEL_a607571858ec4cbd994777505bd9932a"],"layout":"IPY_MODEL_bb8c5bc819614068b44366888ffb8a4a"}},"fd0ec48c1777494db1330046f15411df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a09df2fd5fb545b384b11f3dd0bdca29","placeholder":"​","style":"IPY_MODEL_05afb2c08e2b4f11846603fbaf0c5ae6","value":"100%"}},"73e1d32b91ad4e3dbde0ea0fde008e10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18f437f97f5343599d9b5593a61df051","max":974,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d31809045d7c42658fdb4f6a7574e63b","value":974}},"a607571858ec4cbd994777505bd9932a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2fe7f87b68c4af69490fa2c6fe1c877","placeholder":"​","style":"IPY_MODEL_0972f8cd64b7434ebde2df2527284471","value":" 974/974 [00:00&lt;00:00, 3808.16ex/s]"}},"bb8c5bc819614068b44366888ffb8a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a09df2fd5fb545b384b11f3dd0bdca29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05afb2c08e2b4f11846603fbaf0c5ae6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18f437f97f5343599d9b5593a61df051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d31809045d7c42658fdb4f6a7574e63b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2fe7f87b68c4af69490fa2c6fe1c877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0972f8cd64b7434ebde2df2527284471":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e746583984604841af1b915815ad5122":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8444af0a0acd47e19387ad10ce3e3421","IPY_MODEL_1af30c238a704725a4770642bb0ac145","IPY_MODEL_6df14b5b97a64ebdbc811a93b08509e3"],"layout":"IPY_MODEL_047f7a79b4e746fc88ecc447069fda1a"}},"8444af0a0acd47e19387ad10ce3e3421":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b585fc2ec7af43699c42556a126da98f","placeholder":"​","style":"IPY_MODEL_d5d18d803999477e9d73b757680e18d6","value":"100%"}},"1af30c238a704725a4770642bb0ac145":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c872bd09f1547bab82558cb6e88a94a","max":455,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3e8a23f816149b8bece1751cb3700e8","value":455}},"6df14b5b97a64ebdbc811a93b08509e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84a619a3af6d43489a17e2c63c232ec7","placeholder":"​","style":"IPY_MODEL_dca221db046744dd8e519dae0c2ca1b0","value":" 455/455 [00:00&lt;00:00, 2776.88ex/s]"}},"047f7a79b4e746fc88ecc447069fda1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b585fc2ec7af43699c42556a126da98f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5d18d803999477e9d73b757680e18d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c872bd09f1547bab82558cb6e88a94a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e8a23f816149b8bece1751cb3700e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84a619a3af6d43489a17e2c63c232ec7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dca221db046744dd8e519dae0c2ca1b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Using Domain and Task Adaptive Pretraining with Tranformer Adapters\n","--Talk about the basis of the project--"],"metadata":{"id":"szInH7fcxUtG"}},{"cell_type":"markdown","source":["## Installation\n","--We need to create a enviorment.yaml to install all the correct libraries--"],"metadata":{"id":"9-bKPrJJx0dg"}},{"cell_type":"code","source":["# test saving"],"metadata":{"id":"B_H4BBfJgRlK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test cell number 1"],"metadata":{"id":"c6VodMGrf1yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yy1CA_GwxNSy","executionInfo":{"status":"ok","timestamp":1650216411306,"user_tz":240,"elapsed":24095,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"48ac1c78-1078-49b1-bed6-ffb672941fa6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Collecting adapter-transformers\n","  Downloading adapter_transformers-3.0.0-py3-none-any.whl (3.9 MB)\n","\u001b[K     |████████████████████████████████| 3.9 MB 8.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 57.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (1.21.5)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.8 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 55.0 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->adapter-transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->adapter-transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->adapter-transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, adapter-transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed adapter-transformers-3.0.0 huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1\n","Collecting datasets\n","  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n","\u001b[K     |████████████████████████████████| 325 kB 27.7 MB/s \n","\u001b[?25hCollecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 56.5 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 60.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 57.3 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 63.3 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 67.8 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 71.1 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.8 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}],"source":["# hi this is tony can you see it\n","!pip install numpy\n","!pip install pandas\n","# !pip install transformers --You don't want to have both transformers and adapter-transformers, it caueses issues. fyi adapter-transformers is actually a fork of transformers!\n","!pip install -U adapter-transformers\n","!pip install datasets"]},{"cell_type":"code","source":["\n","from datasets import list_datasets, load_dataset, list_metrics, load_metric\n","from transformers import RobertaTokenizer\n","from transformers import (RobertaConfig, RobertaModelWithHeads, RobertaModel, \n","  RobertaAdapterModel, TrainingArguments, AdapterTrainer, EvalPrediction)\n","from transformers import DataCollatorForLanguageModeling\n","import numpy as np\n","import torch"],"metadata":{"id":"gilzn2oWIhvt","executionInfo":{"status":"ok","timestamp":1650221766991,"user_tz":240,"elapsed":800,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["# Load and Process Data"],"metadata":{"id":"p1zYszsCkqlz"}},{"cell_type":"code","source":["# cs_domain_name = 's2orc'\n","# cs_domain_dataset = load_dataset(cs_domain_name)\n","# print(cs_domain_dataset.num_rows)\n","\n","scierc_name = 'nsusemiehl/SciERC'\n","scierc_dataset = load_dataset(scierc_name)\n","# print(scierc_dataset.num_rows)\n","\n","# acl_arc_name = 'zapsdcn/citation_intent'\n","# acl_arc_dataset = load_dataset(acl_arc_name)\n","# print(acl_arc_dataset.num_rows)\n","# print(scierc_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["6fc3d23c401a4109aa4c13f0f9c3dda9","3e6a27c04c9647e59bde8f8919b27ed1","331e4f67839640e290c6c806bd2de719","263de68477424e9fabbcc1cc02e3983f","a600825e8dc74d59b70ba7c0b05f5ec9","a267ac3dad9b43e5ab9355a2821ea855","cb65442a86244f13b109f321f295497b","5809ef0a7d334e6aabab89792c3fefa8","cc810e4058ee4ec4a9ccaea3794c90d6","84424a3d295f49f6ad3cb5b4784a2977","dbfa6b32fcc24c0fb28f7d627a1c37a0"]},"id":"CFWNDRpVPt_5","executionInfo":{"status":"ok","timestamp":1650220790648,"user_tz":240,"elapsed":3946,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"5d91cbdf-6eb6-4dee-d7a4-f17dff97e7ab"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Using custom data configuration nsusemiehl--SciERC-b7b410772d85970a\n","Reusing dataset json (/root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc3d23c401a4109aa4c13f0f9c3dda9"}},"metadata":{}}]},{"cell_type":"code","source":["# scierc_dataset.max"],"metadata":{"id":"rYXmzZk5vWag","executionInfo":{"status":"ok","timestamp":1650220790649,"user_tz":240,"elapsed":7,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","def encode_batch(batch):\n","  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n","  return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n","\n","def add_masked_labels(examples):\n","  examples[\"labels\"] = examples[\"input_ids\"].copy()\n","  return examples\n","\n","def create_masked_dataset(dataset):\n","  # Encode the input data\n","  # NOTE: num_proc does not seem to work, for some reason it can't find the tokenizer\n","  dataset_masked = dataset.map(\n","      encode_batch, \n","      batched=True, \n","      remove_columns=dataset['train'].column_names)\n","  \n","  dataset_masked = dataset_masked.map(add_masked_labels, batched=True)\n","  dataset_masked.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","  return dataset_masked\n","\n","def create_finetune_dataset(dataset):\n","  # Encode the input data\n","  dataset_finetune = dataset.map(encode_batch, batched=True)\n","  # The transformers model expects the target class column to be named \"labels\"\n","  dataset_finetune = dataset_finetune.rename_column(\"label\", 'labels')\n","  # Transform to pytorch tensors and only output the required columns\n","  label_to_int = { \"COMPARE\": 0, \"CONJUNCTION\": 1, \"EVALUATE-FOR\": 2, \"FEATURE-OF\": 3, \"HYPONYM-OF\": 4, \"PART-OF\": 5, \"USED-FOR\": 6,}\n","  dataset_finetune = dataset_finetune.map(lambda example: {\"labels\": label_to_int[example['labels']]})\n","  dataset_finetune.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","  return dataset_finetune\n","\n","scierc_dataset_masked = create_masked_dataset(scierc_dataset)\n","scierc_dataset_finetune = create_finetune_dataset(scierc_dataset)\n","\n","# Collater adds padding in the form of EOS tokens, makes data augmentations of random masking ('mlm_probability)\n","tokenizer.pad_token = tokenizer.eos_token\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":883,"referenced_widgets":["26592c2ce3b64d379c49a59b002d68bc","04786ad40b8a4fcfb5b11e1ea059be21","f0ebeca5e6f84e5f890929fc93656613","f76d7ffa66e54970a16bdafc0b02b0cb","d71acf9e067b4762ae39502490a93efd","ff5cb95207394f86a558e38c85b08a3c","17cabfba4e524a19a2d01ce3399021a1","036483b7590a4cad987b8c42285fcfe6","65f4dac699c441dfa199161e937df51c","7dd6783b350a4dd8b07f36f5c3119d9d","fe01d87e820740fc87e2c60cf8f0f744","4e770d4a9e3641b8a2a4e7c90afb57a9","fd0ec48c1777494db1330046f15411df","73e1d32b91ad4e3dbde0ea0fde008e10","a607571858ec4cbd994777505bd9932a","bb8c5bc819614068b44366888ffb8a4a","a09df2fd5fb545b384b11f3dd0bdca29","05afb2c08e2b4f11846603fbaf0c5ae6","18f437f97f5343599d9b5593a61df051","d31809045d7c42658fdb4f6a7574e63b","a2fe7f87b68c4af69490fa2c6fe1c877","0972f8cd64b7434ebde2df2527284471","e746583984604841af1b915815ad5122","8444af0a0acd47e19387ad10ce3e3421","1af30c238a704725a4770642bb0ac145","6df14b5b97a64ebdbc811a93b08509e3","047f7a79b4e746fc88ecc447069fda1a","b585fc2ec7af43699c42556a126da98f","d5d18d803999477e9d73b757680e18d6","6c872bd09f1547bab82558cb6e88a94a","f3e8a23f816149b8bece1751cb3700e8","84a619a3af6d43489a17e2c63c232ec7","dca221db046744dd8e519dae0c2ca1b0"]},"id":"TBXW8Lgum_18","executionInfo":{"status":"ok","timestamp":1650221411341,"user_tz":240,"elapsed":13172,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"6696b1d4-b941-4f14-f544-13b8d3193f89"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-172554b0a3034545.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-3f6d03ba447e4b4a.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-c2fa901d2ca0934f.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-60d885253c04b8aa.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-fcf074ca7e66f566.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-583e76ca45bcfc47.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-bbd9033318a591fd.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-58df345273b451d5.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/nsusemiehl--SciERC-b7b410772d85970a/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-4097f34dfdc38876.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3219 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26592c2ce3b64d379c49a59b002d68bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/974 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e770d4a9e3641b8a2a4e7c90afb57a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/455 [00:00<?, ?ex/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e746583984604841af1b915815ad5122"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Initialize Model"],"metadata":{"id":"Nuu-TNTGl6Lq"}},{"cell_type":"code","source":["config = RobertaConfig.from_pretrained(\n","    \"roberta-base\",\n","    # num_labels=num_of_labels,\n",")\n","model = RobertaAdapterModel.from_pretrained(\n","    \"roberta-base\",\n","    config=config,\n",")\n","# Add adapter\n","model.add_adapter(\"sci_erc\")\n","# Add a matching language model head\n","model.add_masked_lm_head(\n","    \"sci_erc\",\n",")\n","# Activate the adapter\n","# model.set_active_adapters(\"sci_erc\")\n","model.train_adapter('sci_erc')\n","\n","training_args = TrainingArguments(\n","    learning_rate=2e-5,\n","    num_train_epochs=1,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    logging_steps=10,\n","    output_dir=\"./training_output/pretraining\",\n","    overwrite_output_dir=True,\n","    # The next line is important to ensure the dataset labels are properly passed to the model\n","    remove_unused_columns=True,\n","    evaluation_strategy = 'steps',\n","    # load_best_model_at_end = True,\n",")\n","\n","# Adding Support for Tensorboard, supposedly you don't have to do this, but I find that it doesn't work\n","# from torch.utils.tensorboard import SummaryWriter\n","# from transformers.integrations import TensorBoardCallback\n","# writer = SummaryWriter()\n","# writer = TensorBoardCallback(writer)\n","\n","trainer = AdapterTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=scierc_dataset_masked[\"train\"],\n","    eval_dataset=scierc_dataset_masked[\"validation\"],\n","    data_collator=data_collator\n","     \n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRMOKwY2lWHL","executionInfo":{"status":"ok","timestamp":1650220806052,"user_tz":240,"elapsed":4207,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"ab3ce0ed-4565-40e3-b003-f978957dda80"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaAdapterModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaAdapterModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Adding adapter 'sci_erc'.\n","Adding head 'sci_erc' with config {'head_type': 'masked_lm', 'vocab_size': 50265, 'layers': 2, 'activation_function': 'gelu', 'layer_norm': True, 'bias': True, 'shift_labels': False, 'label2id': None}.\n","using `logging_steps` to initialize `eval_steps` to 10\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"VwBANKVilWJx","executionInfo":{"status":"ok","timestamp":1650220965381,"user_tz":240,"elapsed":159343,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"8718271e-c51c-4703-9e31-3e34f51caa73"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 3219\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 202\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='202' max='202' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [202/202 02:39, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>16.757600</td>\n","      <td>16.199280</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>15.845100</td>\n","      <td>15.471549</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>15.274300</td>\n","      <td>14.885592</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>14.678300</td>\n","      <td>14.346587</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>14.230300</td>\n","      <td>13.916084</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>13.697900</td>\n","      <td>13.432474</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>13.229300</td>\n","      <td>12.957411</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>12.841900</td>\n","      <td>12.568501</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>12.507100</td>\n","      <td>12.072706</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>12.087700</td>\n","      <td>11.717537</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>11.726000</td>\n","      <td>11.372360</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>11.463600</td>\n","      <td>11.075576</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>11.037400</td>\n","      <td>10.835409</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>10.884100</td>\n","      <td>10.561087</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>10.669800</td>\n","      <td>10.352686</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>10.548400</td>\n","      <td>10.238280</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>10.409200</td>\n","      <td>10.143484</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>10.327500</td>\n","      <td>10.088708</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>10.195100</td>\n","      <td>10.023530</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>10.206200</td>\n","      <td>9.999566</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 16\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=202, training_loss=12.40911869011303, metrics={'train_runtime': 159.7065, 'train_samples_per_second': 20.156, 'train_steps_per_second': 1.265, 'total_flos': 215534383370496.0, 'train_loss': 12.40911869011303, 'epoch': 1.0})"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["model.save_pretrained(\"tony_pretrained\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZVP9nDglWMc","executionInfo":{"status":"ok","timestamp":1650220967077,"user_tz":240,"elapsed":1704,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"ebf9aa33-f749-4b7b-b6d1-57bdd243d529"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Configuration saved in tony_pretrained/config.json\n","Model weights saved in tony_pretrained/pytorch_model.bin\n"]}]},{"cell_type":"markdown","source":["# Fine Tune"],"metadata":{"id":"5sStDfMJxjW9"}},{"cell_type":"code","source":["# config = RobertaConfig.from_pretrained(\n","#     \"tony_pretrained\",\n","#     num_labels=7,\n","# )\n","# model = RobertaAdapterModel.from_pretrained(\n","#     \"tony_pretrained\",\n","#     config=config,\n","# )\n","\n","model.add_classification_head(\n","    \"sci_erc\",\n","    num_labels=7,\n","    overwrite_ok=True,\n","    id2label={0:'COMPARE', 1:'CONJUNCTION', 2:'EVALUATE-FOR', \n","              3:'FEATURE-OF', 4:'HYPONYM-OF', 5:'PART-OF', 6:'USED-FOR'}\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9QrHQv_lWPM","executionInfo":{"status":"ok","timestamp":1650221926210,"user_tz":240,"elapsed":345,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"3191f67f-9032-4fbc-8fbd-cdb3a1747b7f"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["Adding head 'sci_erc' with config {'head_type': 'classification', 'num_labels': 7, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'COMPARE': 0, 'CONJUNCTION': 1, 'EVALUATE-FOR': 2, 'FEATURE-OF': 3, 'HYPONYM-OF': 4, 'PART-OF': 5, 'USED-FOR': 6}, 'use_pooler': False, 'bias': True}.\n"]}]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    learning_rate=1e-4,\n","    num_train_epochs=50,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    logging_steps=200,\n","    output_dir=\"./training_output\",\n","    overwrite_output_dir=True,\n","    # The next line is important to ensure the dataset labels are properly passed to the model\n","    remove_unused_columns=False,\n","    evaluation_strategy = 'steps',\n","    # load_best_model_at_end = True,\n",")\n","\n","# adding f1 metric\n","metric = load_metric('f1')\n","def compute_accuracy(EvalPrediction):\n","  logits, labels = EvalPrediction\n","  predictions = np.argmax(logits, axis=-1)\n","  return metric.compute(predictions=predictions, references=labels, average= 'macro')\n","# def compute_accuracy(p: EvalPrediction):\n","#   preds = np.argmax(p.predictions, axis=1)\n","#   return {\"acc\": (preds == p.label_ids).mean()}\n","trainer = AdapterTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=scierc_dataset_finetune[\"train\"],\n","    eval_dataset=scierc_dataset_finetune[\"validation\"],\n","    compute_metrics=compute_accuracy,    \n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae7tycLDlWRs","executionInfo":{"status":"ok","timestamp":1650221957285,"user_tz":240,"elapsed":1274,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"7ab7e0a5-e47a-4c59-b90f-0e4acee86367"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["using `logging_steps` to initialize `eval_steps` to 200\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWW5l4v24Wm9","executionInfo":{"status":"ok","timestamp":1650221958890,"user_tz":240,"elapsed":3,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}},"outputId":"4fcdf8b7-2d42-4088-f5f3-5c2c9a06afd2"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"id":"ni20CVw7lWUB","outputId":"daa1dc41-9fd0-4cba-e65e-bb73d7807036"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 3219\n","  Num Epochs = 50\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 5050\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='214' max='5050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 214/5050 01:37 < 36:57, 2.18 it/s, Epoch 2.11/50]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>200</td>\n","      <td>1.166100</td>\n","      <td>0.883533</td>\n","      <td>0.475697</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 455\n","  Batch size = 32\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"Ev7rCYA-lWWk","executionInfo":{"status":"aborted","timestamp":1650220967079,"user_tz":240,"elapsed":11,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"mMTs86g3lWZE","executionInfo":{"status":"aborted","timestamp":1650220967080,"user_tz":240,"elapsed":12,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Hr0x8-i3lWbd","executionInfo":{"status":"ok","timestamp":1650219627050,"user_tz":240,"elapsed":13,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"RMkEm10qlWd7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"xVBGd_4OENjt","executionInfo":{"status":"ok","timestamp":1650216459244,"user_tz":240,"elapsed":13,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"q_xldPNGAUOQ","executionInfo":{"status":"ok","timestamp":1650216459244,"user_tz":240,"elapsed":11,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"q-073kxhFZNN","executionInfo":{"status":"aborted","timestamp":1650216470871,"user_tz":240,"elapsed":11,"user":{"displayName":"Tony Nelson","userId":"03833824924952174318"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"TiqCFPTSd6IZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LamemjW2d6K3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"YkN-Wqrxd6Ne"},"execution_count":null,"outputs":[]}]}
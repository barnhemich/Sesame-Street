{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "# %conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "# %pip install -U adapter-transformers\n",
    "# %conda install -y -c conda-forge tensorboard\n",
    "# %pip install optuna\n",
    "# %pip install tqdm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nsusemiehl--SciERC-f57c64a52b9c80c0\n",
      "Reusing dataset json (C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "100%|██████████| 3/3 [00:00<00:00, 999.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 3219, 'test': 974, 'validation': 455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "scierc_name = 'nsusemiehl/SciERC'\n",
    "scierc_dataset = load_dataset(scierc_name)\n",
    "print(scierc_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'We present two [[ methods ]] for capturing << nonstationary chaos >> , then present a few examples including biological signals , ocean waves and traffic flow .',\n",
       " 'label': 'USED-FOR',\n",
       " 'metadata': [3, 3, 6, 7]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scierc_dataset['train'][255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block creates dataset for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-74c87c445e04c867.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-876e0d37d233bb91.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-ecd8f07822814f57.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-b972bbb5f00d5d6e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-40cee27cca22a664.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-2ba76227dbf9fc66.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# Tokenize the set for the transformer\n",
    "def encode_batch_pretraining(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Encode the input data\n",
    "# NOTE: num_proc does not seem to work, for some reason it can't find the tokenizer\n",
    "scierc_dataset_pretraining = scierc_dataset.map(encode_batch_pretraining, \n",
    "                                    batched=True, \n",
    "                                    remove_columns=scierc_dataset['train'].column_names, \n",
    "                                    )\n",
    "\n",
    "# We make the labels the same as the input as this is language learning \n",
    "def add_labels(examples):\n",
    "  examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "  return examples\n",
    "  \n",
    "scierc_dataset_pretraining = scierc_dataset_pretraining.map(add_labels, batched=True)\n",
    "scierc_dataset_pretraining.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collater adds padding in the form of EOS tokens, makes data augmentations of random masking ('mlm_probability)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating the dataset for task finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMPARE' 'CONJUNCTION' 'EVALUATE-FOR' 'FEATURE-OF' 'HYPONYM-OF'\n",
      " 'PART-OF' 'USED-FOR']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of labels\n",
    "import numpy as np\n",
    "labels = np.unique(np.array(scierc_dataset['train']['label']))\n",
    "num_of_labels = labels.size\n",
    "\n",
    "print(labels)\n",
    "print(num_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-3fa4decd4606a523.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-4d2e52dbe4cdbad6.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-214c6724dd02783d.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'The agreement in question involves number in [[ nouns ]] and << reflexive pronouns >> and is syntactic rather than semantic in nature because grammatical number in English , like grammatical gender in languages such as French , is partly arbitrary .',\n",
       " 'label': 1,\n",
       " 'metadata': [7, 7, 9, 10]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding the labels\n",
    "def encode_labels(dataset):\n",
    "    for i in range(num_of_labels):\n",
    "        if dataset['label'] == labels[i]:\n",
    "            dataset['label'] = i\n",
    "    return dataset\n",
    "\n",
    "scierc_dataset = scierc_dataset.map(encode_labels)\n",
    "scierc_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-6c719cda162c2a70.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-a2e89e74a8a70442.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-1e077601566683c7.arrow\n"
     ]
    }
   ],
   "source": [
    "def encode_batch_finetuning(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Encode the input data\n",
    "scierc_dataset_finetuning = scierc_dataset.map(encode_batch_finetuning, batched=True)\n",
    "# The transformers model expects the target class column to be named \"labels\"\n",
    "scierc_dataset_finetuning = scierc_dataset_finetuning.rename_column(\"label\", 'labels')\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "scierc_dataset_finetuning.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaAdapterModel\n",
    "\n",
    "def model_init(adapter_name = 'default_adapter', \n",
    "               num_lables = 0, \n",
    "               pretraining = False,\n",
    "               load_adapter = False,\n",
    "               adapter_dir = 'path'):\n",
    "    \"\"\"Creates a new roBERTa model with the given name for its adapter.\n",
    "\n",
    "    Args:\n",
    "        adapter_name (str): The name of the adapter to load/create. Defaults to 'default_adapter'.\n",
    "        num_lables (int, optional): The number of labels for classification task. Defaults to 0.\n",
    "        pretraining (bool, optional): Whether to create a model for pretraining or classification. Defaults to False.\n",
    "        load_adapter (bool, optional): Whether to load an adapter with the adapter_name given or create a new one. Defaults to False.\n",
    "        adapter_dir (str, optional): Directory to load the adapter. If load_adapter you need to specify this.  Defaults to 'path'.\n",
    "\n",
    "    Returns:\n",
    "        RobertaAdapterModel: A roBERTA model with an adapter added to it.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pretraining:\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            # num_labels=num_of_labels,*-8536.22.03\n",
    "        )\n",
    "        model = RobertaAdapterModel.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            config=config,\n",
    "        )\n",
    "        if load_adapter:\n",
    "            # Add new adapter\n",
    "            model.load_adapter(adapter_dir)\n",
    "\n",
    "        else:\n",
    "            # Add new adapter\n",
    "            model.add_adapter(adapter_name)\n",
    "            \n",
    "        # Add a matching classification head\n",
    "        model.add_masked_lm_head(adapter_name)\n",
    "            \n",
    "    else:\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            num_labels=num_lables,\n",
    "        )\n",
    "        model = RobertaAdapterModel.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            config=config,\n",
    "        )\n",
    "        \n",
    "        if load_adapter:\n",
    "            # Add new adapter\n",
    "            model.load_adapter(adapter_dir)\n",
    "\n",
    "        else:\n",
    "            # Add new adapter\n",
    "            model.add_adapter(adapter_name)\n",
    "            \n",
    "        # Add a matching classification head\n",
    "        model.add_classification_head(\n",
    "                adapter_name,\n",
    "                num_labels=num_lables,\n",
    "                id2label={0:'COMPARE', 1:'CONJUNCTION', 2:'EVALUATE-FOR', \n",
    "                        3:'FEATURE-OF', 4:'HYPONYM-OF', 5:'PART-OF', 6:'USED-FOR'},\n",
    "                overwrite_ok = True)\n",
    "            \n",
    "    # Activate the adapter\n",
    "    model.train_adapter(adapter_name)    \n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraining Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "from datasets import load_metric\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "\n",
    "import json\n",
    "\n",
    "def pretraining_loop(num_models, training_args, dataset, \n",
    "                     data_collator, adapter_name, \n",
    "                    #  DAPT_n_TAPT, TAPT_dataset\n",
    "                     ):\n",
    "    \"\"\"The Loop for running num_models number of models to determine run to run variance. Will run the model \n",
    "        and evaluate.\n",
    "\n",
    "    Args:\n",
    "        num_models (int): Number of models to loop through\n",
    "        training_args (transformers.TrainingArguments): The arguments to pass to the trainer\n",
    "        dataset (dataset): The dataset to train on\n",
    "        data_collator (data_collator): The data collator for the trainer to use\n",
    "        adapter_name (str): Name of the adapter to create\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(num_models):\n",
    "        adapter = f\"{adapter_name}_{i}\"\n",
    "        model = model_init(adapter_name = adapter, pretraining=True)\n",
    "        \n",
    "        writer = SummaryWriter(log_dir= f'runs/{adapter}')\n",
    "        writer = TensorBoardCallback(writer)\n",
    "\n",
    "        trainer = AdapterTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"validation\"],\n",
    "            data_collator=data_collator,  \n",
    "            callbacks=[writer] \n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        f = open(f\"{training_args.output_dir}/evaulations.txt\", \"a\")\n",
    "        f.write(adapter)\n",
    "        f.write(json.dumps(trainer.evaluate(dataset['test'])))\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "        \n",
    "        model.save_all_adapters(training_args.output_dir, with_head=False)\n",
    "        # model.save_pretrained(f\"{adapter_name}\")\n",
    "        \n",
    "        # if DAPT_n_TAPT:\n",
    "        #     trainer = AdapterTrainer(\n",
    "        #         model=model,\n",
    "        #         args=training_args,\n",
    "        #         train_dataset=TAPT_dataset[\"train\"],\n",
    "        #         eval_dataset=TAPT_dataset[\"validation\"],\n",
    "        #         data_collator=data_collator,  \n",
    "        #         callbacks=[writer] \n",
    "        #     )\n",
    "            \n",
    "        #     trainer.train()\n",
    "        \n",
    "        #     f = open(\"DAPT_TAPT_evaulations.txt\", \"a\")\n",
    "        #     f.write(adapter_name)\n",
    "        #     f.write(trainer.evaluate(TAPT_dataset['test']))\n",
    "        #     f.write('\\n')\n",
    "        #     f.close()\n",
    "            \n",
    "        #     model.save_pretrained(f\"{adapter_name}_DAPT_TAPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./training_output/pretraining/DAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100,\n",
    "    gradient_accumulation_steps = 64,\n",
    "    warmup_ratio = 0.06,\n",
    "    weight_decay=0.01,\n",
    "    adam_epsilon = 1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                #  dataset = DAPT_dataset, TODO: Need to add DAPT training set\n",
    "                 data_collator = data_collator, \n",
    "                 adapter_name = \"DAPT_sci-erc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT+TAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/pretraining/TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100,\n",
    "    gradient_accumulation_steps = 8,\n",
    "    warmup_ratio = 0.06,\n",
    "    # load_best_model_at_end = True,\n",
    "    weight_decay=0.01,\n",
    "    adam_epsilon = 1e-6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1180/1200 [1:08:51<01:07,  3.37s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.2076, 'learning_rate': 1.7730496453900712e-06, 'epoch': 98.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 98%|█████████▊| 1180/1200 [1:08:54<01:07,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.05110502243042, 'eval_runtime': 2.7725, 'eval_samples_per_second': 164.111, 'eval_steps_per_second': 5.41, 'epoch': 98.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1190/1200 [1:09:27<00:35,  3.56s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.221, 'learning_rate': 8.865248226950356e-07, 'epoch': 99.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 99%|█████████▉| 1190/1200 [1:09:30<00:35,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.058102130889893, 'eval_runtime': 2.7155, 'eval_samples_per_second': 167.559, 'eval_steps_per_second': 5.524, 'epoch': 99.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [1:10:01<00:00,  3.20s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.9237, 'learning_rate': 0.0, 'epoch': 99.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 1200/1200 [1:10:04<00:00,  3.20s/it]Saving model checkpoint to ./training_output/pretraining/TAPT\\checkpoint-1200\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\head_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.0362467765808105, 'eval_runtime': 2.6884, 'eval_samples_per_second': 169.243, 'eval_steps_per_second': 5.579, 'epoch': 99.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-1200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 1200/1200 [1:10:05<00:00,  3.50s/it]\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4205.2974, 'train_samples_per_second': 76.546, 'train_steps_per_second': 0.285, 'train_loss': 6.185284856160481, 'epoch': 99.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:05<00:00,  5.48it/s]\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\TAPT_sci-erc_0\\pytorch_model_head.bin\n"
     ]
    }
   ],
   "source": [
    "pretraining_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_pretraining, \n",
    "                 data_collator = data_collator, \n",
    "                 adapter_name = \"TAPT_sci-erc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('f1')\n",
    "\n",
    "def compute_metric(EvalPrediction):\n",
    "  \n",
    "  logits, labels = EvalPrediction\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  return metric.compute(predictions=predictions, references=labels, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_loop(num_models, training_args, dataset, adapter_name, num_labels, load_adapter = False, adapter_dir = 'Path'):\n",
    "\n",
    "    for i in range(num_models):\n",
    "        adapter = f\"{adapter_name}_{i}\"\n",
    "        model = model_init(adapter_name = adapter, num_lables = num_labels, pretraining=False, load_adapter = load_adapter, adapter_dir = f\"{adapter_dir}/{adapter}\")\n",
    "        \n",
    "        writer = SummaryWriter(log_dir= f'runs/{adapter}')\n",
    "        writer = TensorBoardCallback(writer)\n",
    "\n",
    "        trainer = AdapterTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"validation\"],\n",
    "            callbacks=[writer],\n",
    "            compute_metrics = compute_metric \n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        f = open(f\"{training_args.output_dir}/evaulations.txt\", \"a\")\n",
    "        f.write(adapter)\n",
    "        f.write(json.dumps(trainer.evaluate(dataset['test'])))\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "        \n",
    "        # model.save_pretrained(f\"{adapter_name}\")\n",
    "        model.save_all_adapters(training_args.output_dir)\n",
    "        \n",
    "        trainer.remove_callback(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./training_output/finetuning/DAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"DAPT_sci-erc\",\n",
    "                 load_adapter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT+TAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/finetuning/DAPT_TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"DAPT_TAPT_sci-erc\",\n",
    "                 load_adapter = True,\n",
    "                 adapter_dir = \"./training_output/pretraining/DAPT_TAPT\",\n",
    "                 num_labels = num_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./training_output/finetuning/TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100,\n",
    "    lr_scheduler_type = 'constant',\n",
    "    log_level  = 'error'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7400/10100 [13:56<04:32,  9.90it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-7400\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 73%|███████▎  | 7401/10100 [13:56<05:35,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3206, 'learning_rate': 2e-05, 'epoch': 36.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 7426/10100 [13:58<04:35,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2375, 'learning_rate': 2e-05, 'epoch': 36.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7452/10100 [14:01<04:30,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2776, 'learning_rate': 2e-05, 'epoch': 36.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7473/10100 [14:03<04:23,  9.97it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 74%|███████▍  | 7475/10100 [14:05<18:52,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5524800419807434, 'eval_f1': 0.7594198593368782, 'eval_runtime': 1.4823, 'eval_samples_per_second': 306.946, 'eval_steps_per_second': 19.564, 'epoch': 37.0}\n",
      "{'loss': 0.2088, 'learning_rate': 2e-05, 'epoch': 37.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7500/10100 [14:07<04:36,  9.41it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-7500\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 74%|███████▍  | 7501/10100 [14:08<05:36,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.227, 'learning_rate': 2e-05, 'epoch': 37.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 7526/10100 [14:10<04:36,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2796, 'learning_rate': 2e-05, 'epoch': 37.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 7551/10100 [14:13<04:37,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2343, 'learning_rate': 2e-05, 'epoch': 37.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7576/10100 [14:15<04:23,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2014, 'learning_rate': 2e-05, 'epoch': 37.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 7600/10100 [14:18<04:11,  9.94it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-7600\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 75%|███████▌  | 7601/10100 [14:18<05:11,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2863, 'learning_rate': 2e-05, 'epoch': 37.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7626/10100 [14:21<04:24,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1951, 'learning_rate': 2e-05, 'epoch': 37.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7651/10100 [14:23<04:26,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.22, 'learning_rate': 2e-05, 'epoch': 37.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7675/10100 [14:26<04:21,  9.26it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2345, 'learning_rate': 2e-05, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 76%|███████▌  | 7677/10100 [14:28<18:20,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45766589045524597, 'eval_f1': 0.807259337132667, 'eval_runtime': 1.5574, 'eval_samples_per_second': 292.151, 'eval_steps_per_second': 18.621, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7700/10100 [14:30<04:18,  9.29it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-7700\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 76%|███████▌  | 7701/10100 [14:30<05:13,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2734, 'learning_rate': 2e-05, 'epoch': 38.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 7726/10100 [14:33<04:17,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2015, 'learning_rate': 2e-05, 'epoch': 38.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7751/10100 [14:36<04:17,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1968, 'learning_rate': 2e-05, 'epoch': 38.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7776/10100 [14:38<04:14,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2004, 'learning_rate': 2e-05, 'epoch': 38.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7800/10100 [14:41<04:08,  9.26it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-7800\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 77%|███████▋  | 7801/10100 [14:41<05:02,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2257, 'learning_rate': 2e-05, 'epoch': 38.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7826/10100 [14:44<04:12,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2022, 'learning_rate': 2e-05, 'epoch': 38.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7851/10100 [14:47<04:21,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2568, 'learning_rate': 2e-05, 'epoch': 38.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7876/10100 [14:50<04:14,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2464, 'learning_rate': 2e-05, 'epoch': 38.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7877/10100 [14:50<04:10,  8.89it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 78%|███████▊  | 7879/10100 [14:51<17:07,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47187650203704834, 'eval_f1': 0.8158251532007458, 'eval_runtime': 1.5854, 'eval_samples_per_second': 286.986, 'eval_steps_per_second': 18.291, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7900/10100 [14:54<03:57,  9.27it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-7900\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-7900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 78%|███████▊  | 7901/10100 [14:54<04:50,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2005, 'learning_rate': 2e-05, 'epoch': 39.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7926/10100 [14:57<03:59,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1754, 'learning_rate': 2e-05, 'epoch': 39.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 7951/10100 [14:59<03:53,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2119, 'learning_rate': 2e-05, 'epoch': 39.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7976/10100 [15:02<03:55,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2584, 'learning_rate': 2e-05, 'epoch': 39.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 8000/10100 [15:05<03:46,  9.28it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8000\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 79%|███████▉  | 8001/10100 [15:05<04:38,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2469, 'learning_rate': 2e-05, 'epoch': 39.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 8026/10100 [15:08<03:47,  9.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.29, 'learning_rate': 2e-05, 'epoch': 39.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 8051/10100 [15:10<03:43,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2206, 'learning_rate': 2e-05, 'epoch': 39.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 8076/10100 [15:13<03:41,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3293, 'learning_rate': 2e-05, 'epoch': 39.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 8079/10100 [15:13<03:40,  9.16it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 80%|████████  | 8081/10100 [15:15<15:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4250684082508087, 'eval_f1': 0.794255993814634, 'eval_runtime': 1.5985, 'eval_samples_per_second': 284.65, 'eval_steps_per_second': 18.143, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8100/10100 [15:17<03:56,  8.46it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8100\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1587, 'learning_rate': 2e-05, 'epoch': 40.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8126/10100 [15:20<03:33,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.184, 'learning_rate': 2e-05, 'epoch': 40.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8151/10100 [15:23<03:34,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2016, 'learning_rate': 2e-05, 'epoch': 40.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8176/10100 [15:26<03:28,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1989, 'learning_rate': 2e-05, 'epoch': 40.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8200/10100 [15:28<03:24,  9.30it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8200\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 81%|████████  | 8201/10100 [15:28<04:10,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2291, 'learning_rate': 2e-05, 'epoch': 40.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 8226/10100 [15:31<03:29,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1948, 'learning_rate': 2e-05, 'epoch': 40.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8251/10100 [15:34<03:22,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2377, 'learning_rate': 2e-05, 'epoch': 40.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8276/10100 [15:36<03:14,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2656, 'learning_rate': 2e-05, 'epoch': 40.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8281/10100 [15:37<03:12,  9.43it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 82%|████████▏ | 8283/10100 [15:39<13:27,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.46412673592567444, 'eval_f1': 0.8202669390250374, 'eval_runtime': 1.5264, 'eval_samples_per_second': 298.089, 'eval_steps_per_second': 18.999, 'epoch': 41.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8300/10100 [15:40<03:14,  9.27it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8300\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 82%|████████▏ | 8301/10100 [15:41<03:57,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2833, 'learning_rate': 2e-05, 'epoch': 41.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8326/10100 [15:43<03:11,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1625, 'learning_rate': 2e-05, 'epoch': 41.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8351/10100 [15:46<03:09,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.217, 'learning_rate': 2e-05, 'epoch': 41.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8376/10100 [15:49<03:03,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1454, 'learning_rate': 2e-05, 'epoch': 41.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8400/10100 [15:51<03:02,  9.33it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8400\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 83%|████████▎ | 8401/10100 [15:51<03:42,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2788, 'learning_rate': 2e-05, 'epoch': 41.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8426/10100 [15:54<02:58,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2171, 'learning_rate': 2e-05, 'epoch': 41.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 8451/10100 [15:57<02:56,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2611, 'learning_rate': 2e-05, 'epoch': 41.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8476/10100 [15:59<02:55,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2199, 'learning_rate': 2e-05, 'epoch': 41.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8483/10100 [16:00<02:52,  9.39it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 84%|████████▍ | 8485/10100 [16:02<11:56,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44670742750167847, 'eval_f1': 0.8049900510035624, 'eval_runtime': 1.5234, 'eval_samples_per_second': 298.677, 'eval_steps_per_second': 19.037, 'epoch': 42.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8500/10100 [16:03<02:52,  9.30it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8500\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 84%|████████▍ | 8501/10100 [16:03<03:29,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2161, 'learning_rate': 2e-05, 'epoch': 42.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8526/10100 [16:06<02:48,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2055, 'learning_rate': 2e-05, 'epoch': 42.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8551/10100 [16:09<02:45,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.182, 'learning_rate': 2e-05, 'epoch': 42.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8576/10100 [16:11<02:43,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2121, 'learning_rate': 2e-05, 'epoch': 42.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8600/10100 [16:14<02:39,  9.40it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8600\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 85%|████████▌ | 8601/10100 [16:14<03:13,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1728, 'learning_rate': 2e-05, 'epoch': 42.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 8626/10100 [16:17<02:37,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1195, 'learning_rate': 2e-05, 'epoch': 42.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8651/10100 [16:19<02:37,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.216, 'learning_rate': 2e-05, 'epoch': 42.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8676/10100 [16:22<02:34,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2188, 'learning_rate': 2e-05, 'epoch': 42.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8685/10100 [16:23<02:32,  9.31it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 86%|████████▌ | 8687/10100 [16:25<10:38,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44976162910461426, 'eval_f1': 0.8110861079664099, 'eval_runtime': 1.5544, 'eval_samples_per_second': 292.715, 'eval_steps_per_second': 18.657, 'epoch': 43.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8700/10100 [16:26<02:38,  8.85it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8700\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 86%|████████▌ | 8701/10100 [16:26<03:09,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.21, 'learning_rate': 2e-05, 'epoch': 43.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 8726/10100 [16:29<02:29,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2324, 'learning_rate': 2e-05, 'epoch': 43.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8751/10100 [16:32<02:29,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1523, 'learning_rate': 2e-05, 'epoch': 43.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8776/10100 [16:35<02:26,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1766, 'learning_rate': 2e-05, 'epoch': 43.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8800/10100 [16:37<02:21,  9.18it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8800\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 87%|████████▋ | 8801/10100 [16:37<02:50,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1856, 'learning_rate': 2e-05, 'epoch': 43.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8826/10100 [16:40<02:17,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2266, 'learning_rate': 2e-05, 'epoch': 43.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8851/10100 [16:43<02:13,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2434, 'learning_rate': 2e-05, 'epoch': 43.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8876/10100 [16:45<02:13,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1767, 'learning_rate': 2e-05, 'epoch': 43.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8887/10100 [16:46<02:10,  9.31it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 88%|████████▊ | 8889/10100 [16:48<09:01,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5068959593772888, 'eval_f1': 0.8230098116369308, 'eval_runtime': 1.5354, 'eval_samples_per_second': 296.34, 'eval_steps_per_second': 18.888, 'epoch': 44.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8900/10100 [16:49<02:17,  8.74it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-8900\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-8900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 88%|████████▊ | 8901/10100 [16:49<02:41,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.208, 'learning_rate': 2e-05, 'epoch': 44.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8926/10100 [16:52<02:06,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2388, 'learning_rate': 2e-05, 'epoch': 44.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 8951/10100 [16:55<02:03,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.178, 'learning_rate': 2e-05, 'epoch': 44.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8976/10100 [16:57<02:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1762, 'learning_rate': 2e-05, 'epoch': 44.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 9000/10100 [17:00<01:56,  9.43it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9000\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 89%|████████▉ | 9001/10100 [17:00<02:22,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2522, 'learning_rate': 2e-05, 'epoch': 44.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 9026/10100 [17:03<01:55,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1677, 'learning_rate': 2e-05, 'epoch': 44.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 9051/10100 [17:05<01:51,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2279, 'learning_rate': 2e-05, 'epoch': 44.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 9076/10100 [17:08<01:49,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2668, 'learning_rate': 2e-05, 'epoch': 44.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 9089/10100 [17:09<01:45,  9.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 90%|█████████ | 9091/10100 [17:11<07:27,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5605481863021851, 'eval_f1': 0.7889465844504617, 'eval_runtime': 1.5264, 'eval_samples_per_second': 298.089, 'eval_steps_per_second': 18.999, 'epoch': 45.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9100/10100 [17:12<02:02,  8.16it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9100\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 90%|█████████ | 9101/10100 [17:12<02:21,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2227, 'learning_rate': 2e-05, 'epoch': 45.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9126/10100 [17:15<01:44,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1843, 'learning_rate': 2e-05, 'epoch': 45.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9151/10100 [17:18<01:43,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1778, 'learning_rate': 2e-05, 'epoch': 45.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9176/10100 [17:20<01:39,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1943, 'learning_rate': 2e-05, 'epoch': 45.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9200/10100 [17:23<01:34,  9.51it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9200\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 91%|█████████ | 9201/10100 [17:23<01:55,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2371, 'learning_rate': 2e-05, 'epoch': 45.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 9226/10100 [17:26<01:33,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1814, 'learning_rate': 2e-05, 'epoch': 45.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9251/10100 [17:28<01:31,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1907, 'learning_rate': 2e-05, 'epoch': 45.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9276/10100 [17:31<01:28,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1847, 'learning_rate': 2e-05, 'epoch': 45.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9291/10100 [17:33<01:25,  9.42it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 92%|█████████▏| 9293/10100 [17:34<05:59,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4775365889072418, 'eval_f1': 0.8255346557453428, 'eval_runtime': 1.5284, 'eval_samples_per_second': 297.699, 'eval_steps_per_second': 18.974, 'epoch': 46.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9300/10100 [17:35<01:53,  7.05it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9300\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 92%|█████████▏| 9301/10100 [17:35<02:04,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1534, 'learning_rate': 2e-05, 'epoch': 46.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9326/10100 [17:38<01:22,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.195, 'learning_rate': 2e-05, 'epoch': 46.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9351/10100 [17:40<01:20,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2435, 'learning_rate': 2e-05, 'epoch': 46.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9376/10100 [17:43<01:18,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2143, 'learning_rate': 2e-05, 'epoch': 46.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9400/10100 [17:46<01:13,  9.53it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9400\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9400\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 93%|█████████▎| 9401/10100 [17:46<01:29,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1066, 'learning_rate': 2e-05, 'epoch': 46.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9426/10100 [17:48<01:12,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.166, 'learning_rate': 2e-05, 'epoch': 46.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 9451/10100 [17:51<01:09,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1802, 'learning_rate': 2e-05, 'epoch': 46.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9476/10100 [17:54<01:06,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1839, 'learning_rate': 2e-05, 'epoch': 46.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9493/10100 [17:56<01:03,  9.49it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 94%|█████████▍| 9495/10100 [17:57<04:26,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5255916118621826, 'eval_f1': 0.8225592312935263, 'eval_runtime': 1.5164, 'eval_samples_per_second': 300.057, 'eval_steps_per_second': 19.125, 'epoch': 47.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9500/10100 [17:58<01:45,  5.69it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9500\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9500\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 94%|█████████▍| 9501/10100 [17:58<01:47,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2224, 'learning_rate': 2e-05, 'epoch': 47.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9526/10100 [18:01<01:02,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1786, 'learning_rate': 2e-05, 'epoch': 47.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 9551/10100 [18:03<00:59,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.16, 'learning_rate': 2e-05, 'epoch': 47.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 9576/10100 [18:06<00:56,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1923, 'learning_rate': 2e-05, 'epoch': 47.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 9600/10100 [18:09<00:54,  9.14it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9600\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9600\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 95%|█████████▌| 9601/10100 [18:09<01:06,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2614, 'learning_rate': 2e-05, 'epoch': 47.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 9626/10100 [18:12<00:51,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1923, 'learning_rate': 2e-05, 'epoch': 47.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9651/10100 [18:14<00:48,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1615, 'learning_rate': 2e-05, 'epoch': 47.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9676/10100 [18:17<00:46,  9.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1925, 'learning_rate': 2e-05, 'epoch': 47.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9695/10100 [18:19<00:43,  9.21it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 96%|█████████▌| 9697/10100 [18:21<03:04,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4788797199726105, 'eval_f1': 0.8264477293573206, 'eval_runtime': 1.5704, 'eval_samples_per_second': 289.73, 'eval_steps_per_second': 18.466, 'epoch': 48.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9700/10100 [18:21<01:39,  4.02it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9700\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9700\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 96%|█████████▌| 9701/10100 [18:21<01:33,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1301, 'learning_rate': 2e-05, 'epoch': 48.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 9726/10100 [18:24<00:43,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1645, 'learning_rate': 2e-05, 'epoch': 48.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9751/10100 [18:27<00:37,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1975, 'learning_rate': 2e-05, 'epoch': 48.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9776/10100 [18:29<00:34,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1741, 'learning_rate': 2e-05, 'epoch': 48.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9800/10100 [18:32<00:32,  9.30it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9800\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9800\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 97%|█████████▋| 9801/10100 [18:32<00:39,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1739, 'learning_rate': 2e-05, 'epoch': 48.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9826/10100 [18:35<00:29,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2203, 'learning_rate': 2e-05, 'epoch': 48.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9851/10100 [18:38<00:27,  9.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1973, 'learning_rate': 2e-05, 'epoch': 48.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9876/10100 [18:40<00:24,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1252, 'learning_rate': 2e-05, 'epoch': 48.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9897/10100 [18:43<00:21,  9.29it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n",
      "                                                    \n",
      " 98%|█████████▊| 9899/10100 [18:44<01:30,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4998268783092499, 'eval_f1': 0.8095116139931723, 'eval_runtime': 1.5564, 'eval_samples_per_second': 292.338, 'eval_steps_per_second': 18.633, 'epoch': 49.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9900/10100 [18:44<01:13,  2.73it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-9900\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-9900\\TAPT_sci-erc_0\\pytorch_model_head.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1516, 'learning_rate': 2e-05, 'epoch': 49.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9926/10100 [18:47<00:18,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1883, 'learning_rate': 2e-05, 'epoch': 49.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 9951/10100 [18:50<00:16,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1324, 'learning_rate': 2e-05, 'epoch': 49.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9976/10100 [18:53<00:13,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1158, 'learning_rate': 2e-05, 'epoch': 49.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 10000/10100 [18:55<00:10,  9.28it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-10000\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10000\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 99%|█████████▉| 10001/10100 [18:55<00:12,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1571, 'learning_rate': 2e-05, 'epoch': 49.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 10026/10100 [18:58<00:08,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1625, 'learning_rate': 2e-05, 'epoch': 49.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 10051/10100 [19:01<00:05,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1399, 'learning_rate': 2e-05, 'epoch': 49.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 10076/10100 [19:03<00:02,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2008, 'learning_rate': 2e-05, 'epoch': 49.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10100/10100 [19:06<00:00,  9.36it/s]Saving model checkpoint to ./training_output/finetuning/TAPT\\checkpoint-10100\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\checkpoint-10100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0939, 'learning_rate': 2e-05, 'epoch': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 10100/10100 [19:08<00:00,  9.36it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 10100/10100 [19:08<00:00,  8.80it/s]\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5171557664871216, 'eval_f1': 0.8222261813681893, 'eval_runtime': 1.5634, 'eval_samples_per_second': 291.028, 'eval_steps_per_second': 18.549, 'epoch': 50.0}\n",
      "{'train_runtime': 1148.1544, 'train_samples_per_second': 140.181, 'train_steps_per_second': 8.797, 'train_loss': 0.5226877824622805, 'epoch': 50.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:03<00:00, 18.78it/s]\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/finetuning/TAPT\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/finetuning/TAPT\\TAPT_sci-erc_0\\pytorch_model_head.bin\n"
     ]
    }
   ],
   "source": [
    "finetuning_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"TAPT_sci-erc\",\n",
    "                 load_adapter = True,\n",
    "                 adapter_dir = \"./training_output/pretraining/TAPT\",\n",
    "                 num_labels = num_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./training_output/finetuning/No_Pretrain\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100,\n",
    "    lr_scheduler_type = 'constant',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"sci-erc\",\n",
    "                 load_adapter = False,\n",
    "                 num_labels = num_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2469684d7fc26b35c5046a1b9c559332af356cccfef9c5dca4231e653832987c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

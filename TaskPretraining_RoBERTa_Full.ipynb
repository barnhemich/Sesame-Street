{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "# %conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "%pip install -U adapter-transformers\n",
    "%conda install -y -c conda-forge tensorboard\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nsusemiehl--SciERC-f57c64a52b9c80c0\n",
      "Reusing dataset json (C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "100%|██████████| 3/3 [00:00<00:00, 999.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 3219, 'test': 974, 'validation': 455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "scierc_name = 'nsusemiehl/SciERC'\n",
    "scierc_dataset = load_dataset(scierc_name)\n",
    "print(scierc_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'We present two [[ methods ]] for capturing << nonstationary chaos >> , then present a few examples including biological signals , ocean waves and traffic flow .',\n",
       " 'label': 'USED-FOR',\n",
       " 'metadata': [3, 3, 6, 7]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scierc_dataset['train'][255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block creates dataset for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-74c87c445e04c867.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-876e0d37d233bb91.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-ecd8f07822814f57.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-b972bbb5f00d5d6e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-40cee27cca22a664.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-2ba76227dbf9fc66.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# Tokenize the set for the transformer\n",
    "def encode_batch_pretraining(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Encode the input data\n",
    "# NOTE: num_proc does not seem to work, for some reason it can't find the tokenizer\n",
    "scierc_dataset_pretraining = scierc_dataset.map(encode_batch_pretraining, \n",
    "                                    batched=True, \n",
    "                                    remove_columns=scierc_dataset['train'].column_names, \n",
    "                                    )\n",
    "\n",
    "# We make the labels the same as the input as this is language learning \n",
    "def add_labels(examples):\n",
    "  examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "  return examples\n",
    "  \n",
    "scierc_dataset_pretraining = scierc_dataset_pretraining.map(add_labels, batched=True)\n",
    "scierc_dataset_pretraining.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collater adds padding in the form of EOS tokens, makes data augmentations of random masking ('mlm_probability)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating the dataset for task finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMPARE' 'CONJUNCTION' 'EVALUATE-FOR' 'FEATURE-OF' 'HYPONYM-OF'\n",
      " 'PART-OF' 'USED-FOR']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of labels\n",
    "import numpy as np\n",
    "labels = np.unique(np.array(scierc_dataset['train']['label']))\n",
    "num_of_labels = labels.size\n",
    "\n",
    "print(labels)\n",
    "print(num_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-3fa4decd4606a523.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-4d2e52dbe4cdbad6.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-214c6724dd02783d.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'The agreement in question involves number in [[ nouns ]] and << reflexive pronouns >> and is syntactic rather than semantic in nature because grammatical number in English , like grammatical gender in languages such as French , is partly arbitrary .',\n",
       " 'label': 1,\n",
       " 'metadata': [7, 7, 9, 10]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding the labels\n",
    "def encode_labels(dataset):\n",
    "    for i in range(num_of_labels):\n",
    "        if dataset['label'] == labels[i]:\n",
    "            dataset['label'] = i\n",
    "    return dataset\n",
    "\n",
    "scierc_dataset = scierc_dataset.map(encode_labels)\n",
    "scierc_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-6c719cda162c2a70.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-a2e89e74a8a70442.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-1e077601566683c7.arrow\n"
     ]
    }
   ],
   "source": [
    "def encode_batch_finetuning(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Encode the input data\n",
    "scierc_dataset_finetuning = scierc_dataset.map(encode_batch_finetuning, batched=True)\n",
    "# The transformers model expects the target class column to be named \"labels\"\n",
    "scierc_dataset_finetuning = scierc_dataset_finetuning.rename_column(\"label\", 'labels')\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "scierc_dataset_finetuning.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaAdapterModel\n",
    "\n",
    "def model_init(adapter_name = 'default_adapter', \n",
    "               num_lables = 0, \n",
    "               pretraining = False,\n",
    "               load_adapter = False,\n",
    "               adapter_dir = 'path'):\n",
    "    \"\"\"Creates a new roBERTa model with the given name for its adapter.\n",
    "\n",
    "    Args:\n",
    "        adapter_name (str): The name of the adapter to load/create. Defaults to 'default_adapter'.\n",
    "        num_lables (int, optional): The number of labels for classification task. Defaults to 0.\n",
    "        pretraining (bool, optional): Whether to create a model for pretraining or classification. Defaults to False.\n",
    "        load_adapter (bool, optional): Whether to load an adapter with the adapter_name given or create a new one. Defaults to False.\n",
    "        adapter_dir (str, optional): Directory to load the adapter. If load_adapter you need to specify this.  Defaults to 'path'.\n",
    "\n",
    "    Returns:\n",
    "        RobertaAdapterModel: A roBERTA model with an adapter added to it.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pretraining:\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            # num_labels=num_of_labels,*-8536.22.03\n",
    "        )\n",
    "        model = RobertaAdapterModel.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            config=config,\n",
    "        )\n",
    "        if load_adapter:\n",
    "            # Add new adapter\n",
    "            model.load_adapter(adapter_dir)\n",
    "\n",
    "        else:\n",
    "            # Add new adapter\n",
    "            model.add_adapter(adapter_name)\n",
    "            \n",
    "        # Add a matching classification head\n",
    "        model.add_masked_lm_head(adapter_name)\n",
    "            \n",
    "    else:\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            num_labels=num_lables,\n",
    "        )\n",
    "        model = RobertaAdapterModel.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            config=config,\n",
    "        )\n",
    "        \n",
    "        if load_adapter:\n",
    "            # Add new adapter\n",
    "            model.load_adapter(adapter_dir)\n",
    "\n",
    "        else:\n",
    "            # Add new adapter\n",
    "            model.add_adapter(adapter_name)\n",
    "            \n",
    "        # Add a matching classification head\n",
    "        model.add_classification_head(\n",
    "                adapter_name,\n",
    "                num_labels=num_lables,\n",
    "                id2label={0:'COMPARE', 1:'CONJUNCTION', 2:'EVALUATE-FOR', \n",
    "                        3:'FEATURE-OF', 4:'HYPONYM-OF', 5:'PART-OF', 6:'USED-FOR'},\n",
    "                overwrite_ok = True)\n",
    "            \n",
    "    # Activate the adapter\n",
    "    model.train_adapter(adapter_name)    \n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraining Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "from datasets import load_metric\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "\n",
    "import json\n",
    "\n",
    "def pretraining_loop(num_models, training_args, dataset, \n",
    "                     data_collator, adapter_name, \n",
    "                    #  DAPT_n_TAPT, TAPT_dataset\n",
    "                     ):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        num_models (_type_): _description_\n",
    "        training_args (_type_): _description_\n",
    "        dataset (_type_): _description_\n",
    "        data_collator (_type_): _description_\n",
    "        adapter_name (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(num_models):\n",
    "        adapter = f\"{adapter_name}_{i}\"\n",
    "        model = model_init(adapter_name = adapter, pretraining=True)\n",
    "        \n",
    "        writer = SummaryWriter(log_dir= f'runs/{adapter}')\n",
    "        writer = TensorBoardCallback(writer)\n",
    "\n",
    "        trainer = AdapterTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"validation\"],\n",
    "            data_collator=data_collator,  \n",
    "            callbacks=[writer] \n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        f = open(f\"{training_args.output_dir}/evaulations.txt\", \"a\")\n",
    "        f.write(adapter)\n",
    "        f.write(json.dumps(trainer.evaluate(dataset['test'])))\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "        \n",
    "        model.save_all_adapters(training_args.output_dir, with_head=False)\n",
    "        # model.save_pretrained(f\"{adapter_name}\")\n",
    "        \n",
    "        # if DAPT_n_TAPT:\n",
    "        #     trainer = AdapterTrainer(\n",
    "        #         model=model,\n",
    "        #         args=training_args,\n",
    "        #         train_dataset=TAPT_dataset[\"train\"],\n",
    "        #         eval_dataset=TAPT_dataset[\"validation\"],\n",
    "        #         data_collator=data_collator,  \n",
    "        #         callbacks=[writer] \n",
    "        #     )\n",
    "            \n",
    "        #     trainer.train()\n",
    "        \n",
    "        #     f = open(\"DAPT_TAPT_evaulations.txt\", \"a\")\n",
    "        #     f.write(adapter_name)\n",
    "        #     f.write(trainer.evaluate(TAPT_dataset['test']))\n",
    "        #     f.write('\\n')\n",
    "        #     f.close()\n",
    "            \n",
    "        #     model.save_pretrained(f\"{adapter_name}_DAPT_TAPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./training_output/pretraining/DAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100,\n",
    "    gradient_accumulation_steps = 64,\n",
    "    warmup_ratio = 0.06\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                #  dataset = DAPT_dataset, TODO: Need to add DAPT training set\n",
    "                 data_collator = data_collator, \n",
    "                 adapter_name = \"DAPT_sci-erc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT+TAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=100,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/pretraining/TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100,\n",
    "    gradient_accumulation_steps = 8,\n",
    "    warmup_ratio = 0.06,\n",
    "    # load_best_model_at_end = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaAdapterModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are adding a <class 'transformers.integrations.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "AdapterTrainerCallback\n",
      "C:\\Users\\The Doctor\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3219\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 1200\n",
      "  1%|          | 10/1200 [00:32<1:02:40,  3.16s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 17.8218, 'learning_rate': 1.388888888888889e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  1%|          | 10/1200 [00:35<1:02:40,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 17.37076759338379, 'eval_runtime': 2.6434, 'eval_samples_per_second': 172.127, 'eval_steps_per_second': 5.675, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1200 [01:07<1:02:08,  3.16s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 18.0503, 'learning_rate': 2.777777777777778e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  2%|▏         | 20/1200 [01:10<1:02:08,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 16.33852767944336, 'eval_runtime': 2.6634, 'eval_samples_per_second': 170.833, 'eval_steps_per_second': 5.632, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 30/1200 [01:43<1:02:30,  3.21s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 16.847, 'learning_rate': 4.166666666666667e-05, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  2%|▎         | 30/1200 [01:45<1:02:30,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 15.088282585144043, 'eval_runtime': 2.6544, 'eval_samples_per_second': 171.413, 'eval_steps_per_second': 5.651, 'epoch': 2.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1200 [02:18<1:03:55,  3.31s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.319, 'learning_rate': 5.555555555555556e-05, 'epoch': 3.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 40/1200 [02:21<1:03:55,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.4595947265625, 'eval_runtime': 2.6694, 'eval_samples_per_second': 170.449, 'eval_steps_per_second': 5.619, 'epoch': 3.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 50/1200 [02:53<1:07:10,  3.51s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.3959, 'learning_rate': 6.944444444444444e-05, 'epoch': 4.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  4%|▍         | 50/1200 [02:56<1:07:10,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.486201286315918, 'eval_runtime': 2.6589, 'eval_samples_per_second': 171.121, 'eval_steps_per_second': 5.641, 'epoch': 4.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 60/1200 [03:27<59:38,  3.14s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.8082, 'learning_rate': 8.333333333333334e-05, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "  5%|▌         | 60/1200 [03:30<59:38,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.695045471191406, 'eval_runtime': 2.7129, 'eval_samples_per_second': 167.718, 'eval_steps_per_second': 5.529, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 70/1200 [04:02<59:06,  3.14s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 9.8157, 'learning_rate': 9.722222222222223e-05, 'epoch': 5.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "  6%|▌         | 70/1200 [04:05<59:06,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.364571571350098, 'eval_runtime': 2.6625, 'eval_samples_per_second': 170.891, 'eval_steps_per_second': 5.634, 'epoch': 5.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 80/1200 [04:38<58:57,  3.16s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.6135, 'learning_rate': 9.929078014184398e-05, 'epoch': 6.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "  7%|▋         | 80/1200 [04:40<58:57,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.573639869689941, 'eval_runtime': 2.6624, 'eval_samples_per_second': 170.897, 'eval_steps_per_second': 5.634, 'epoch': 6.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 90/1200 [05:13<59:32,  3.22s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.0005, 'learning_rate': 9.840425531914894e-05, 'epoch': 7.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "  8%|▊         | 90/1200 [05:16<59:32,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.161333084106445, 'eval_runtime': 2.6665, 'eval_samples_per_second': 170.634, 'eval_steps_per_second': 5.625, 'epoch': 7.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 100/1200 [05:48<1:00:29,  3.30s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.5853, 'learning_rate': 9.75177304964539e-05, 'epoch': 8.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  8%|▊         | 100/1200 [05:51<1:00:29,  3.30s/it]Saving model checkpoint to ./training_output/pretraining/TAPT\\checkpoint-100\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\head_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.86968994140625, 'eval_runtime': 2.666, 'eval_samples_per_second': 170.669, 'eval_steps_per_second': 5.626, 'epoch': 8.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "  9%|▉         | 110/1200 [06:25<1:03:43,  3.51s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.3055, 'learning_rate': 9.663120567375887e-05, 'epoch': 9.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  9%|▉         | 110/1200 [06:27<1:03:43,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.635702610015869, 'eval_runtime': 2.6589, 'eval_samples_per_second': 171.122, 'eval_steps_per_second': 5.641, 'epoch': 9.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 120/1200 [06:58<56:06,  3.12s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.696, 'learning_rate': 9.574468085106384e-05, 'epoch': 9.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|█         | 120/1200 [07:01<56:06,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.582831859588623, 'eval_runtime': 2.6634, 'eval_samples_per_second': 170.833, 'eval_steps_per_second': 5.632, 'epoch': 9.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 130/1200 [07:33<56:07,  3.15s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.9756, 'learning_rate': 9.485815602836879e-05, 'epoch': 10.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 11%|█         | 130/1200 [07:36<56:07,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.478057384490967, 'eval_runtime': 2.6639, 'eval_samples_per_second': 170.799, 'eval_steps_per_second': 5.631, 'epoch': 10.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 140/1200 [08:09<55:44,  3.15s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.8633, 'learning_rate': 9.397163120567376e-05, 'epoch': 11.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 12%|█▏        | 140/1200 [08:11<55:44,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.315354347229004, 'eval_runtime': 2.6504, 'eval_samples_per_second': 171.672, 'eval_steps_per_second': 5.66, 'epoch': 11.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 150/1200 [08:44<56:01,  3.20s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.7847, 'learning_rate': 9.308510638297873e-05, 'epoch': 12.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 12%|█▎        | 150/1200 [08:47<56:01,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.320107936859131, 'eval_runtime': 2.6564, 'eval_samples_per_second': 171.283, 'eval_steps_per_second': 5.647, 'epoch': 12.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 160/1200 [09:19<57:13,  3.30s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.6586, 'learning_rate': 9.21985815602837e-05, 'epoch': 13.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 13%|█▎        | 160/1200 [09:22<57:13,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.201133728027344, 'eval_runtime': 2.6669, 'eval_samples_per_second': 170.607, 'eval_steps_per_second': 5.624, 'epoch': 13.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 170/1200 [09:55<1:00:02,  3.50s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.632, 'learning_rate': 9.131205673758866e-05, 'epoch': 14.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 14%|█▍        | 170/1200 [09:57<1:00:02,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.158675193786621, 'eval_runtime': 2.6644, 'eval_samples_per_second': 170.769, 'eval_steps_per_second': 5.63, 'epoch': 14.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 180/1200 [10:28<52:59,  3.12s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.1577, 'learning_rate': 9.042553191489363e-05, 'epoch': 14.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 15%|█▌        | 180/1200 [10:31<52:59,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.166477680206299, 'eval_runtime': 2.6594, 'eval_samples_per_second': 171.09, 'eval_steps_per_second': 5.64, 'epoch': 14.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 190/1200 [11:03<52:45,  3.13s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.4852, 'learning_rate': 8.953900709219858e-05, 'epoch': 15.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 16%|█▌        | 190/1200 [11:06<52:45,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.042835235595703, 'eval_runtime': 2.6664, 'eval_samples_per_second': 170.641, 'eval_steps_per_second': 5.626, 'epoch': 15.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 200/1200 [11:39<52:32,  3.15s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.4219, 'learning_rate': 8.865248226950354e-05, 'epoch': 16.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 17%|█▋        | 200/1200 [11:41<52:32,  3.15s/it]Saving model checkpoint to ./training_output/pretraining/TAPT\\checkpoint-200\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\head_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.978287220001221, 'eval_runtime': 2.6724, 'eval_samples_per_second': 170.257, 'eval_steps_per_second': 5.613, 'epoch': 16.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-200\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 18%|█▊        | 210/1200 [12:15<52:59,  3.21s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.4007, 'learning_rate': 8.77659574468085e-05, 'epoch': 17.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 18%|█▊        | 210/1200 [12:18<52:59,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.98807954788208, 'eval_runtime': 2.6624, 'eval_samples_per_second': 170.897, 'eval_steps_per_second': 5.634, 'epoch': 17.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 220/1200 [12:50<53:51,  3.30s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.33, 'learning_rate': 8.687943262411347e-05, 'epoch': 18.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 18%|█▊        | 220/1200 [12:53<53:51,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.9161553382873535, 'eval_runtime': 2.6865, 'eval_samples_per_second': 169.367, 'eval_steps_per_second': 5.584, 'epoch': 18.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 230/1200 [13:26<56:20,  3.49s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.3319, 'learning_rate': 8.599290780141844e-05, 'epoch': 19.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 19%|█▉        | 230/1200 [13:28<56:20,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.889645576477051, 'eval_runtime': 2.6654, 'eval_samples_per_second': 170.705, 'eval_steps_per_second': 5.628, 'epoch': 19.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 240/1200 [13:59<49:54,  3.12s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.8787, 'learning_rate': 8.510638297872341e-05, 'epoch': 19.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 240/1200 [14:02<49:54,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.9296722412109375, 'eval_runtime': 2.6614, 'eval_samples_per_second': 170.961, 'eval_steps_per_second': 5.636, 'epoch': 19.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 250/1200 [14:34<49:39,  3.14s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.2291, 'learning_rate': 8.421985815602838e-05, 'epoch': 20.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 21%|██        | 250/1200 [14:37<49:39,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.8891072273254395, 'eval_runtime': 2.6474, 'eval_samples_per_second': 171.866, 'eval_steps_per_second': 5.666, 'epoch': 20.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 260/1200 [15:10<49:28,  3.16s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.2064, 'learning_rate': 8.333333333333334e-05, 'epoch': 21.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 22%|██▏       | 260/1200 [15:12<49:28,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.852653980255127, 'eval_runtime': 2.6624, 'eval_samples_per_second': 170.897, 'eval_steps_per_second': 5.634, 'epoch': 21.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 270/1200 [15:45<49:38,  3.20s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.1534, 'learning_rate': 8.244680851063831e-05, 'epoch': 22.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 22%|██▎       | 270/1200 [15:48<49:38,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.81445837020874, 'eval_runtime': 2.6504, 'eval_samples_per_second': 171.672, 'eval_steps_per_second': 5.66, 'epoch': 22.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 280/1200 [16:20<50:32,  3.30s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.125, 'learning_rate': 8.156028368794327e-05, 'epoch': 23.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|██▎       | 280/1200 [16:23<50:32,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.849323749542236, 'eval_runtime': 2.6634, 'eval_samples_per_second': 170.833, 'eval_steps_per_second': 5.632, 'epoch': 23.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 290/1200 [16:55<52:54,  3.49s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.1219, 'learning_rate': 8.067375886524823e-05, 'epoch': 24.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 24%|██▍       | 290/1200 [16:58<52:54,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.7037858963012695, 'eval_runtime': 2.6879, 'eval_samples_per_second': 169.274, 'eval_steps_per_second': 5.58, 'epoch': 24.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 300/1200 [17:29<47:23,  3.16s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.6887, 'learning_rate': 7.978723404255319e-05, 'epoch': 24.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 25%|██▌       | 300/1200 [17:32<47:23,  3.16s/it]Saving model checkpoint to ./training_output/pretraining/TAPT\\checkpoint-300\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\head_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.7752509117126465, 'eval_runtime': 2.6756, 'eval_samples_per_second': 170.058, 'eval_steps_per_second': 5.606, 'epoch': 24.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-300\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      " 26%|██▌       | 310/1200 [18:06<46:57,  3.17s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.0436, 'learning_rate': 7.890070921985815e-05, 'epoch': 25.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 26%|██▌       | 310/1200 [18:08<46:57,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.671374320983887, 'eval_runtime': 2.6644, 'eval_samples_per_second': 170.769, 'eval_steps_per_second': 5.63, 'epoch': 25.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 320/1200 [18:41<46:32,  3.17s/it]  ***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.0292, 'learning_rate': 7.801418439716312e-05, 'epoch': 26.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 27%|██▋       | 320/1200 [18:44<46:32,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.668488025665283, 'eval_runtime': 2.4452, 'eval_samples_per_second': 186.077, 'eval_steps_per_second': 6.134, 'epoch': 26.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 330/1200 [19:16<46:18,  3.19s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.9657, 'learning_rate': 7.712765957446809e-05, 'epoch': 27.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 28%|██▊       | 330/1200 [19:19<46:18,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.674651145935059, 'eval_runtime': 2.6684, 'eval_samples_per_second': 170.513, 'eval_steps_per_second': 5.621, 'epoch': 27.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 340/1200 [19:51<47:23,  3.31s/it]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.9914, 'learning_rate': 7.624113475177306e-05, 'epoch': 28.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 28%|██▊       | 340/1200 [19:54<47:23,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.573325157165527, 'eval_runtime': 2.6539, 'eval_samples_per_second': 171.445, 'eval_steps_per_second': 5.652, 'epoch': 28.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 342/1200 [20:00<53:40,  3.75s/it]"
     ]
    }
   ],
   "source": [
    "pretraining_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_pretraining, \n",
    "                 data_collator = data_collator, \n",
    "                 adapter_name = \"TAPT_sci-erc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('f1')\n",
    "\n",
    "def compute_metric(EvalPrediction):\n",
    "  \n",
    "  logits, labels = EvalPrediction\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  return metric.compute(predictions=predictions, references=labels, average= 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_loop(num_models, training_args, dataset, adapter_name, num_labels, load_adapter = False, adapter_dir = 'Path'):\n",
    "\n",
    "    for i in range(num_models):\n",
    "        adapter = f\"{adapter_name}_{i}\"\n",
    "        model = model_init(adapter_name = adapter, num_lables = num_labels, pretraining=False, load_adapter = load_adapter, adapter_dir = f\"{adapter_dir}/{adapter}\")\n",
    "        \n",
    "        writer = SummaryWriter(log_dir= f'runs/{adapter}')\n",
    "        writer = TensorBoardCallback(writer)\n",
    "\n",
    "        trainer = AdapterTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"validation\"],\n",
    "            callbacks=[writer],\n",
    "            compute_metrics = compute_metric \n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        f = open(f\"{training_args.output_dir}/evaulations.txt\", \"a\")\n",
    "        f.write(adapter)\n",
    "        f.write(json.dumps(trainer.evaluate(dataset['test'])))\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "        \n",
    "        # model.save_pretrained(f\"{adapter_name}\")\n",
    "        model.save_all_adapters(training_args.output_dir)\n",
    "        \n",
    "        trainer.remove_callback(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./training_output/finetuning/DAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"DAPT_sci-erc\",\n",
    "                 load_adapter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT+TAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/finetuning/DAPT_TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"DAPT_TAPT_sci-erc\",\n",
    "                 load_adapter = True,\n",
    "                 adapter_dir = \"./training_output/pretraining/DAPT_TAPT\",\n",
    "                 num_labels = num_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    logging_steps=25,\n",
    "    output_dir=\"./training_output/finetuning/TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"TAPT_sci-erc\",\n",
    "                 load_adapter = True,\n",
    "                 adapter_dir = \"./training_output/pretraining/TAPT\",\n",
    "                 num_labels = num_of_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    logging_steps=100,\n",
    "    output_dir=\"./training_output/finetuning/No_Pretrain\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"sci-erc\",\n",
    "                 load_adapter = False,\n",
    "                 num_labels = num_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2469684d7fc26b35c5046a1b9c559332af356cccfef9c5dca4231e653832987c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "%conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch\n",
    "%pip install -U adapter-transformers\n",
    "%conda install -y -c conda-forge tensorboard\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration nsusemiehl--SciERC-f57c64a52b9c80c0\n",
      "Reusing dataset json (C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "100%|██████████| 3/3 [00:00<00:00, 999.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 3219, 'test': 974, 'validation': 455}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "scierc_name = 'nsusemiehl/SciERC'\n",
    "scierc_dataset = load_dataset(scierc_name)\n",
    "print(scierc_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'We present two [[ methods ]] for capturing << nonstationary chaos >> , then present a few examples including biological signals , ocean waves and traffic flow .',\n",
       " 'label': 'USED-FOR',\n",
       " 'metadata': [3, 3, 6, 7]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scierc_dataset['train'][255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block creates dataset for TAPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-068cb547204d3efb.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-527ded298eaa2825.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-2e3b1750e8aa3efd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-06e5711bbfdf297f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-3a9e3e4dea744a82.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-bf8228d2a5bd318f.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def encode_batch_pretraining(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Encode the input data\n",
    "# NOTE: num_proc does not seem to work, for some reason it can't find the tokenizer\n",
    "scierc_dataset_pretraining = scierc_dataset.map(encode_batch_pretraining, \n",
    "                                    batched=True, \n",
    "                                    remove_columns=scierc_dataset['train'].column_names, \n",
    "                                    )\n",
    "\n",
    "def add_labels(examples):\n",
    "  examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "  return examples\n",
    "  \n",
    "scierc_dataset_pretraining = scierc_dataset_pretraining.map(add_labels, batched=True)\n",
    "scierc_dataset_pretraining.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collater adds padding in the form of EOS tokens, makes data augmentations of random masking ('mlm_probability)\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating the dataset for task finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMPARE' 'CONJUNCTION' 'EVALUATE-FOR' 'FEATURE-OF' 'HYPONYM-OF'\n",
      " 'PART-OF' 'USED-FOR']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of labels\n",
    "import numpy as np\n",
    "labels = np.unique(np.array(scierc_dataset['train']['label']))\n",
    "num_of_labels = labels.size\n",
    "\n",
    "print(labels)\n",
    "print(num_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-3fa4decd4606a523.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-4d2e52dbe4cdbad6.arrow\n",
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-214c6724dd02783d.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'The agreement in question involves number in [[ nouns ]] and << reflexive pronouns >> and is syntactic rather than semantic in nature because grammatical number in English , like grammatical gender in languages such as French , is partly arbitrary .',\n",
       " 'label': 1,\n",
       " 'metadata': [7, 7, 9, 10]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding the labels\n",
    "def encode_labels(dataset):\n",
    "    for i in range(num_of_labels):\n",
    "        if dataset['label'] == labels[i]:\n",
    "            dataset['label'] = i\n",
    "    return dataset\n",
    "\n",
    "scierc_dataset = scierc_dataset.map(encode_labels)\n",
    "scierc_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\The Doctor\\.cache\\huggingface\\datasets\\json\\nsusemiehl--SciERC-f57c64a52b9c80c0\\0.0.0\\ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b\\cache-6c719cda162c2a70.arrow\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.69ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.57ba/s]\n"
     ]
    }
   ],
   "source": [
    "def encode_batch_finetuning(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"text\"], max_length=80, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Encode the input data\n",
    "scierc_dataset_finetuning = scierc_dataset.map(encode_batch_finetuning, batched=True)\n",
    "# The transformers model expects the target class column to be named \"labels\"\n",
    "scierc_dataset_finetuning = scierc_dataset_finetuning.rename_column(\"label\", 'labels')\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "scierc_dataset_finetuning.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaAdapterModel\n",
    "\n",
    "def model_init(adapter_name = 'default_adapter', \n",
    "               num_lables = 0, \n",
    "               pretraining = False,\n",
    "               load_adapter = False):\n",
    "    \n",
    "    if pretraining:\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            # num_labels=num_of_labels,\n",
    "        )\n",
    "        model = RobertaAdapterModel.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            config=config,\n",
    "        )\n",
    "        if load_adapter:\n",
    "            # Add new adapter\n",
    "            model.load_adapter(adapter_name)\n",
    "\n",
    "        else:\n",
    "            # Add new adapter\n",
    "            model.add_adapter(adapter_name)\n",
    "            \n",
    "        # Add a matching classification head\n",
    "        model.add_masked_lm_head(adapter_name)\n",
    "            \n",
    "    else:\n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            num_labels=num_of_labels,\n",
    "        )\n",
    "        model = RobertaAdapterModel.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "            config=config,\n",
    "        )\n",
    "        \n",
    "        if load_adapter:\n",
    "            # Add new adapter\n",
    "            model.load_adapter(adapter_name)\n",
    "\n",
    "        else:\n",
    "            # Add new adapter\n",
    "            model.add_adapter(adapter_name)\n",
    "            \n",
    "        # Add a matching classification head\n",
    "        model.add_classification_head(\n",
    "                adapter_name,\n",
    "                num_labels=num_lables,\n",
    "                id2label={0:'COMPARE', 1:'CONJUNCTION', 2:'EVALUATE-FOR', \n",
    "                        3:'FEATURE-OF', 4:'HYPONYM-OF', 5:'PART-OF', 6:'USED-FOR'}\n",
    "                )\n",
    "            \n",
    "    # Activate the adapter\n",
    "    model.train_adapter(adapter_name)    \n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraining Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AdapterTrainer\n",
    "from datasets import load_metric\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "\n",
    "import json\n",
    "\n",
    "def pretraining_loop(num_models, training_args, dataset, \n",
    "                     data_collator, adapter_name, \n",
    "                    #  DAPT_n_TAPT, TAPT_dataset\n",
    "                     ):\n",
    "\n",
    "    for i in range(num_models):\n",
    "        adapter_name = f\"{adapter_name}_{i}\"\n",
    "        model = model_init(adapter_name = adapter_name, pretraining=True)\n",
    "        \n",
    "        writer = SummaryWriter(filename_suffix = adapter_name)\n",
    "        writer = TensorBoardCallback(writer, )\n",
    "\n",
    "        trainer = AdapterTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"validation\"],\n",
    "            data_collator=data_collator,  \n",
    "            callbacks=[writer] \n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        f = open(f\"{training_args.output_dir}/evaulations.txt\", \"a\")\n",
    "        f.write(adapter_name)\n",
    "        f.write(json.dumps(trainer.evaluate(dataset['test'])))\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "        \n",
    "        model.save_adapter(f\"{adapter_name}\")\n",
    "        model.save_pretrained(f\"{adapter_name}\")\n",
    "        \n",
    "        # if DAPT_n_TAPT:\n",
    "        #     trainer = AdapterTrainer(\n",
    "        #         model=model,\n",
    "        #         args=training_args,\n",
    "        #         train_dataset=TAPT_dataset[\"train\"],\n",
    "        #         eval_dataset=TAPT_dataset[\"validation\"],\n",
    "        #         data_collator=data_collator,  \n",
    "        #         callbacks=[writer] \n",
    "        #     )\n",
    "            \n",
    "        #     trainer.train()\n",
    "        \n",
    "        #     f = open(\"DAPT_TAPT_evaulations.txt\", \"a\")\n",
    "        #     f.write(adapter_name)\n",
    "        #     f.write(trainer.evaluate(TAPT_dataset['test']))\n",
    "        #     f.write('\\n')\n",
    "        #     f.close()\n",
    "            \n",
    "        #     model.save_pretrained(f\"{adapter_name}_DAPT_TAPT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/pretraining/DAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                #  dataset = DAPT_dataset, TODO: Need to add DAPT training set\n",
    "                 data_collator = data_collator, \n",
    "                 adapter_name = \"DAPT_sci-erc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT+TAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAPT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/pretraining/TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaAdapterModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are adding a <class 'transformers.integrations.TensorBoardCallback'> to the callbacks of this Trainer, but there is already one. The currentlist of callbacks is\n",
      ":DefaultFlowCallback\n",
      "TensorBoardCallback\n",
      "AdapterTrainerCallback\n",
      "C:\\Users\\The Doctor\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3219\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 101\n",
      " 10%|▉         | 10/101 [00:05<00:39,  2.32it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 16.2717, 'learning_rate': 1.8019801980198022e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 10%|▉         | 10/101 [00:08<00:39,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 15.850793838500977, 'eval_runtime': 2.8516, 'eval_samples_per_second': 159.56, 'eval_steps_per_second': 5.26, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 20/101 [00:12<00:36,  2.21it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.5778, 'learning_rate': 1.6039603960396042e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 20%|█▉        | 20/101 [00:15<00:36,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 15.2877836227417, 'eval_runtime': 3.0007, 'eval_samples_per_second': 151.63, 'eval_steps_per_second': 4.999, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 30/101 [00:20<00:32,  2.16it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.0371, 'learning_rate': 1.405940594059406e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 30%|██▉       | 30/101 [00:23<00:32,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 14.801627159118652, 'eval_runtime': 2.8967, 'eval_samples_per_second': 157.077, 'eval_steps_per_second': 5.178, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 40/101 [00:27<00:27,  2.21it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 14.6546, 'learning_rate': 1.207920792079208e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 40%|███▉      | 40/101 [00:30<00:27,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 14.34333610534668, 'eval_runtime': 2.9422, 'eval_samples_per_second': 154.647, 'eval_steps_per_second': 5.098, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 50/101 [00:34<00:23,  2.19it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 14.1999, 'learning_rate': 1.00990099009901e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 50%|████▉     | 50/101 [00:37<00:23,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 14.028948783874512, 'eval_runtime': 2.7906, 'eval_samples_per_second': 163.045, 'eval_steps_per_second': 5.375, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 60/101 [00:41<00:18,  2.24it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.9206, 'learning_rate': 8.11881188118812e-06, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 59%|█████▉    | 60/101 [00:44<00:18,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.717873573303223, 'eval_runtime': 2.8017, 'eval_samples_per_second': 162.4, 'eval_steps_per_second': 5.354, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 70/101 [00:48<00:13,  2.25it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.5803, 'learning_rate': 6.138613861386139e-06, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 69%|██████▉   | 70/101 [00:51<00:13,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.460526466369629, 'eval_runtime': 2.8192, 'eval_samples_per_second': 161.392, 'eval_steps_per_second': 5.321, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 80/101 [00:55<00:09,  2.21it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.3802, 'learning_rate': 4.158415841584159e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 79%|███████▉  | 80/101 [00:58<00:09,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.32620620727539, 'eval_runtime': 2.8062, 'eval_samples_per_second': 162.14, 'eval_steps_per_second': 5.345, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 90/101 [01:02<00:04,  2.24it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.2446, 'learning_rate': 2.1782178217821785e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 89%|████████▉ | 90/101 [01:05<00:04,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.203391075134277, 'eval_runtime': 2.8954, 'eval_samples_per_second': 157.145, 'eval_steps_per_second': 5.181, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 100/101 [01:09<00:00,  2.22it/s]***** Running Evaluation *****\n",
      "  Num examples = 455\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.1806, 'learning_rate': 1.9801980198019803e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 99%|█████████▉| 100/101 [01:12<00:00,  2.22it/s]Saving model checkpoint to ./training_output/pretraining/TAPT\\checkpoint-100\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\adapter_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\head_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 13.146415710449219, 'eval_runtime': 2.8282, 'eval_samples_per_second': 160.881, 'eval_steps_per_second': 5.304, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\head_config.json\n",
      "Module weights saved in ./training_output/pretraining/TAPT\\checkpoint-100\\TAPT_sci-erc_0\\pytorch_model_head.bin\n",
      "100%|██████████| 101/101 [01:13<00:00,  1.54s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 101/101 [01:13<00:00,  1.37it/s]\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 974\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 73.4952, 'train_samples_per_second': 43.799, 'train_steps_per_second': 1.374, 'train_loss': 14.291752777477303, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:06<00:00,  4.98it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_adapter() missing 1 required positional argument: 'adapter_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\The Doctor\\OneDrive - Georgia Institute of Technology\\Spring 2022\\Deep Learning\\Project\\Sesame-Street\\TaskPretraining_RoBERTa_Full.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000021?line=0'>1</a>\u001b[0m pretraining_loop(num_models \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000021?line=1'>2</a>\u001b[0m                  training_args \u001b[39m=\u001b[39;49m training_args, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000021?line=2'>3</a>\u001b[0m                  dataset \u001b[39m=\u001b[39;49m scierc_dataset_pretraining, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000021?line=3'>4</a>\u001b[0m                  data_collator \u001b[39m=\u001b[39;49m data_collator, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000021?line=4'>5</a>\u001b[0m                  adapter_name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mTAPT_sci-erc\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\The Doctor\\OneDrive - Georgia Institute of Technology\\Spring 2022\\Deep Learning\\Project\\Sesame-Street\\TaskPretraining_RoBERTa_Full.ipynb Cell 14'\u001b[0m in \u001b[0;36mpretraining_loop\u001b[1;34m(num_models, training_args, dataset, data_collator, adapter_name)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000013?line=33'>34</a>\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000013?line=34'>35</a>\u001b[0m f\u001b[39m.\u001b[39mclose()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000013?line=36'>37</a>\u001b[0m model\u001b[39m.\u001b[39;49msave_adapter(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00madapter_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: save_adapter() missing 1 required positional argument: 'adapter_name'"
     ]
    }
   ],
   "source": [
    "pretraining_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_pretraining, \n",
    "                 data_collator = data_collator, \n",
    "                 adapter_name = \"TAPT_sci-erc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuning_loop(num_models, training_args, dataset, adapter_name, load_adapter = False):\n",
    "\n",
    "    for i in range(num_models):\n",
    "        adapter_name = f\"{adapter_name}_{i}\"\n",
    "        model = model_init(adapter_name = adapter_name, pretraining=False, load_adapter = load_adapter)\n",
    "        \n",
    "        writer = SummaryWriter(filename_suffix = adapter_name)\n",
    "        writer = TensorBoardCallback(writer, )\n",
    "\n",
    "        trainer = AdapterTrainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            train_dataset=dataset[\"train\"],\n",
    "            eval_dataset=dataset[\"validation\"],\n",
    "            data_collator=data_collator,  \n",
    "            callbacks=[writer] \n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        f = open(f\"{training_args.output_dir}/evaulations.txt\", \"a\")\n",
    "        f.write(adapter_name)\n",
    "        f.write(trainer.evaluate(dataset['test']))\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "        \n",
    "        model.save_pretrained(f\"{adapter_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/finetuning/DAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"DAPT_sci-erc\",\n",
    "                 load_adapter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAPT+TAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/finetuning/DAPT_TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"DAPT_TAPT_sci-erc\",\n",
    "                 load_adapter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAPT Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 10\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/finetuning/TAPT\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at C:\\Users\\The Doctor/.cache\\huggingface\\transformers\\733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.17.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at C:\\Users\\The Doctor/.cache\\huggingface\\transformers\\51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaAdapterModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file pytorch_adapter.bin or no file adapter_config.json found in directory TAPT_sci-erc_0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\The Doctor\\OneDrive - Georgia Institute of Technology\\Spring 2022\\Deep Learning\\Project\\Sesame-Street\\TaskPretraining_RoBERTa_Full.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000032?line=0'>1</a>\u001b[0m finetuning_loop(num_models \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000032?line=1'>2</a>\u001b[0m                  training_args \u001b[39m=\u001b[39;49m training_args, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000032?line=2'>3</a>\u001b[0m                  dataset \u001b[39m=\u001b[39;49m scierc_dataset_finetuning,  \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000032?line=3'>4</a>\u001b[0m                  adapter_name \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mTAPT_sci-erc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000032?line=4'>5</a>\u001b[0m                  load_adapter \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\The Doctor\\OneDrive - Georgia Institute of Technology\\Spring 2022\\Deep Learning\\Project\\Sesame-Street\\TaskPretraining_RoBERTa_Full.ipynb Cell 24'\u001b[0m in \u001b[0;36mfinetuning_loop\u001b[1;34m(num_models, training_args, dataset, adapter_name, load_adapter)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000023?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_models):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000023?line=3'>4</a>\u001b[0m     adapter_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00madapter_name\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000023?line=4'>5</a>\u001b[0m     model \u001b[39m=\u001b[39m model_init(adapter_name \u001b[39m=\u001b[39;49m adapter_name, pretraining\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, load_adapter \u001b[39m=\u001b[39;49m load_adapter)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000023?line=6'>7</a>\u001b[0m     writer \u001b[39m=\u001b[39m SummaryWriter(filename_suffix \u001b[39m=\u001b[39m adapter_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000023?line=7'>8</a>\u001b[0m     writer \u001b[39m=\u001b[39m TensorBoardCallback(writer, )\n",
      "\u001b[1;32mc:\\Users\\The Doctor\\OneDrive - Georgia Institute of Technology\\Spring 2022\\Deep Learning\\Project\\Sesame-Street\\TaskPretraining_RoBERTa_Full.ipynb Cell 12'\u001b[0m in \u001b[0;36mmodel_init\u001b[1;34m(adapter_name, num_lables, pretraining, load_adapter)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=33'>34</a>\u001b[0m model \u001b[39m=\u001b[39m RobertaAdapterModel\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=34'>35</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mroberta-base\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=35'>36</a>\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=36'>37</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=38'>39</a>\u001b[0m \u001b[39mif\u001b[39;00m load_adapter:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=39'>40</a>\u001b[0m     \u001b[39m# Add new adapter\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=40'>41</a>\u001b[0m     model\u001b[39m.\u001b[39;49mload_adapter(adapter_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=42'>43</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=43'>44</a>\u001b[0m     \u001b[39m# Add new adapter\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/The%20Doctor/OneDrive%20-%20Georgia%20Institute%20of%20Technology/Spring%202022/Deep%20Learning/Project/Sesame-Street/TaskPretraining_RoBERTa_Full.ipynb#ch0000011?line=44'>45</a>\u001b[0m     model\u001b[39m.\u001b[39madd_adapter(adapter_name)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\adapters\\model_mixin.py:913\u001b[0m, in \u001b[0;36mModelWithHeadsAdaptersMixin.load_adapter\u001b[1;34m(self, adapter_name_or_path, config, version, model_name, load_as, source, with_head, custom_weights_loaders, leave_out, id2label, set_active, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=910'>911</a>\u001b[0m \u001b[39mif\u001b[39;00m num_labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=911'>912</a>\u001b[0m     id2label \u001b[39m=\u001b[39m {i: \u001b[39m\"\u001b[39m\u001b[39mLABEL_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_labels)}\n\u001b[1;32m--> <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mload_adapter(\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=913'>914</a>\u001b[0m     adapter_name_or_path,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=914'>915</a>\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=915'>916</a>\u001b[0m     version\u001b[39m=\u001b[39mversion,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=916'>917</a>\u001b[0m     model_name\u001b[39m=\u001b[39mmodel_name,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=917'>918</a>\u001b[0m     load_as\u001b[39m=\u001b[39mload_as,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=918'>919</a>\u001b[0m     source\u001b[39m=\u001b[39msource,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=919'>920</a>\u001b[0m     custom_weights_loaders\u001b[39m=\u001b[39mcustom_weights_loaders,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=920'>921</a>\u001b[0m     leave_out\u001b[39m=\u001b[39mleave_out,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=921'>922</a>\u001b[0m     id2label\u001b[39m=\u001b[39mid2label,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=922'>923</a>\u001b[0m     set_active\u001b[39m=\u001b[39mset_active,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=923'>924</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=924'>925</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\adapters\\model_mixin.py:479\u001b[0m, in \u001b[0;36mModelAdaptersMixin.load_adapter\u001b[1;34m(self, adapter_name_or_path, config, version, model_name, load_as, source, custom_weights_loaders, leave_out, id2label, set_active, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=448'>449</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=449'>450</a>\u001b[0m \u001b[39mLoads a pre-trained pytorch adapter module from the local file system or a remote location.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=450'>451</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=475'>476</a>\u001b[0m \u001b[39m    str: The name with which the adapter was added to the model.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=476'>477</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=477'>478</a>\u001b[0m loader \u001b[39m=\u001b[39m AdapterLoader(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=478'>479</a>\u001b[0m load_dir, load_name \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload(\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=479'>480</a>\u001b[0m     adapter_name_or_path,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=480'>481</a>\u001b[0m     config,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=481'>482</a>\u001b[0m     version,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=482'>483</a>\u001b[0m     model_name,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=483'>484</a>\u001b[0m     load_as,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=484'>485</a>\u001b[0m     source\u001b[39m=\u001b[39msource,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=485'>486</a>\u001b[0m     leave_out\u001b[39m=\u001b[39mleave_out,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=486'>487</a>\u001b[0m     set_active\u001b[39m=\u001b[39mset_active,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=487'>488</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=488'>489</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=489'>490</a>\u001b[0m \u001b[39m# load additional custom weights\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/model_mixin.py?line=490'>491</a>\u001b[0m \u001b[39mif\u001b[39;00m custom_weights_loaders:\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\adapters\\loading.py:420\u001b[0m, in \u001b[0;36mAdapterLoader.load\u001b[1;34m(self, adapter_name_or_path, config, version, model_name, load_as, loading_info, leave_out, set_active, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=417'>418</a>\u001b[0m \u001b[39m# Resolve the weights to be loaded based on the given identifier and the current adapter config\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=418'>419</a>\u001b[0m model_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel_name \u001b[39mor\u001b[39;00m model_name\n\u001b[1;32m--> <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=419'>420</a>\u001b[0m resolved_folder \u001b[39m=\u001b[39m resolve_adapter_path(\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=420'>421</a>\u001b[0m     adapter_name_or_path,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=421'>422</a>\u001b[0m     model_name,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=422'>423</a>\u001b[0m     adapter_config\u001b[39m=\u001b[39mrequested_config,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=423'>424</a>\u001b[0m     version\u001b[39m=\u001b[39mversion,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=424'>425</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=425'>426</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=427'>428</a>\u001b[0m \u001b[39m# Load config of adapter\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/loading.py?line=428'>429</a>\u001b[0m config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_helper\u001b[39m.\u001b[39mload_weights_config(resolved_folder)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\adapters\\utils.py:473\u001b[0m, in \u001b[0;36mresolve_adapter_path\u001b[1;34m(adapter_name_or_path, model_name, adapter_config, version, source, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=470'>471</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m adapter_name_or_path\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=471'>472</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=472'>473</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=473'>474</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNo file \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m or no file \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m found in directory \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=474'>475</a>\u001b[0m                 WEIGHTS_NAME, CONFIG_NAME, adapter_name_or_path\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=475'>476</a>\u001b[0m             )\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=476'>477</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=477'>478</a>\u001b[0m \u001b[39melif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mah\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=478'>479</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pull_from_hub(\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=479'>480</a>\u001b[0m         adapter_name_or_path, model_name, adapter_config\u001b[39m=\u001b[39madapter_config, version\u001b[39m=\u001b[39mversion, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    <a href='file:///c%3A/Users/The%20Doctor/.conda/envs/pytorch/lib/site-packages/transformers/adapters/utils.py?line=480'>481</a>\u001b[0m     )\n",
      "\u001b[1;31mOSError\u001b[0m: No file pytorch_adapter.bin or no file adapter_config.json found in directory TAPT_sci-erc_0"
     ]
    }
   ],
   "source": [
    "finetuning_loop(num_models = 1, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"TAPT_sci-erc\",\n",
    "                 load_adapter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=10,\n",
    "    output_dir=\"./training_output/finetuning/No_Pretrain\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=True,\n",
    "    evaluation_strategy = 'steps',\n",
    "    # load_best_model_at_end = True,\n",
    "    save_steps = 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_loop(num_models = 5, \n",
    "                 training_args = training_args, \n",
    "                 dataset = scierc_dataset_finetuning,  \n",
    "                 adapter_name = \"sci-erc\",\n",
    "                 load_adapter = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2469684d7fc26b35c5046a1b9c559332af356cccfef9c5dca4231e653832987c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
